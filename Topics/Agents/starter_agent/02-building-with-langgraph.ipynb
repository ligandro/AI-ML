{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa533b08-a7bf-46c8-bda8-e3b0e68d7004",
   "metadata": {},
   "source": [
    "# Building with LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5176cc44",
   "metadata": {},
   "source": [
    "## What is LangGraph?\n",
    "\n",
    "**LangGraph** is a library for building stateful, multi-step applications with LLMs using a graph-based approach. It's designed specifically for creating **AI agents** that can:\n",
    "\n",
    "- Maintain conversation state across multiple turns\n",
    "- Make decisions based on context\n",
    "- Use external tools and APIs\n",
    "- Handle complex workflows with conditional logic\n",
    "- Remember past interactions\n",
    "\n",
    "**Key Advantages Over Basic LLM Calls:**\n",
    "\n",
    "1. **State Management** - Built-in conversation memory and context tracking\n",
    "2. **Graph Structure** - Define complex flows with nodes, edges, and conditions\n",
    "3. **Tool Integration** - Seamlessly connect LLMs to external functions\n",
    "4. **Persistence** - Save and restore conversation states\n",
    "5. **Visualization** - See your agent's architecture visually\n",
    "\n",
    "**Use Cases:**\n",
    "- Multi-turn conversational agents\n",
    "- Research assistants with web search\n",
    "- Autonomous task executors\n",
    "- Complex decision-making systems\n",
    "- Customer support bots with memory\n",
    "\n",
    "In this notebook, we'll build increasingly sophisticated agents using local Ollama (llama3.2) instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80480c1a-b9da-487f-9293-8f991ba57dbd",
   "metadata": {},
   "source": [
    "## Building a ChatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2726b556",
   "metadata": {},
   "source": [
    "### Understanding LangGraph Basics\n",
    "\n",
    "**LangGraph** is a framework for building stateful, multi-actor applications with LLMs. It extends LangChain with the ability to create cyclic graphs for agent workflows.\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "**1. StateGraph** - The core structure that manages application state and flow\n",
    "- Defines how data (state) flows between nodes\n",
    "- Manages conversation history and context\n",
    "\n",
    "**2. State (TypedDict)** - Application state definition\n",
    "- `messages: Annotated[list, add_messages]` - Stores conversation history\n",
    "- `add_messages` - Built-in reducer that intelligently merges messages\n",
    "\n",
    "**3. Nodes** - Individual processing units\n",
    "- `chatbot` node - Invokes the LLM with current state\n",
    "- Returns updated state (new messages)\n",
    "\n",
    "**4. Graph Flow**\n",
    "- `set_entry_point(\"chatbot\")` - Where the graph starts\n",
    "- `set_finish_point(\"chatbot\")` - Where the graph ends\n",
    "- `compile()` - Builds the executable graph\n",
    "\n",
    "**Simple ChatBot Architecture:**\n",
    "```\n",
    "START → chatbot node → END\n",
    "```\n",
    "\n",
    "This basic bot takes user input, processes it through the LLM, and returns a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd85174-7bcc-4000-83ba-2874ed15c791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade -q langchain langchain-ollama langchain-community langgraph langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33823fa-9733-449f-829e-2bdf203a7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b4beecb-74ed-44ef-8e0f-bd7019677666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatOllama(model='llama3.2', temperature=0.5)\n",
    "\n",
    "# defining the chatbot node\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# adding the node to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# setting the entry and the finish points\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3359e9-2377-4185-b530-c361d0fb5274",
   "metadata": {},
   "source": [
    "## Visualizing the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db60c50",
   "metadata": {},
   "source": [
    "### Graph Visualization\n",
    "\n",
    "LangGraph provides built-in visualization tools to understand your agent's architecture:\n",
    "\n",
    "**Two Visualization Methods:**\n",
    "\n",
    "1. **Mermaid Diagram (PNG)** - Visual flowchart\n",
    "   - Uses `graph.get_graph().draw_mermaid_png()`\n",
    "   - Shows nodes, edges, and flow direction\n",
    "   - Great for documentation and presentations\n",
    "\n",
    "2. **ASCII Diagram** - Text-based representation\n",
    "   - Uses `graph.get_graph().draw_ascii()`\n",
    "   - Works in any terminal/console\n",
    "   - Useful for debugging and quick inspection\n",
    "\n",
    "**Why Visualize?**\n",
    "- Understand the agent's decision flow\n",
    "- Debug complex multi-node graphs\n",
    "- Communicate design to team members\n",
    "- Verify conditional edges and loops are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652d99be-f2e3-42cb-a9af-a85aef41fce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5566c1-429d-4030-95b2-f95652de39d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4778a311-0a74-42b1-891e-1419babfa99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+  \n",
      "| __start__ |  \n",
      "+-----------+  \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      " +---------+   \n",
      " | chatbot |   \n",
      " +---------+   \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      " +---------+   \n",
      " | __end__ |   \n",
      " +---------+   \n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b64d7-ffed-4dfb-8a78-b9f98c3633ef",
   "metadata": {},
   "source": [
    "## Running the ChatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b243d21",
   "metadata": {},
   "source": [
    "### Interactive Chat Loop\n",
    "\n",
    "**How the ChatBot Runs:**\n",
    "\n",
    "**`graph.stream()`** - Streams graph execution events\n",
    "- Takes input: `{'messages': ('user', user_input)}`\n",
    "- Returns events as the graph processes\n",
    "- Each event contains updated state\n",
    "\n",
    "**Event Processing:**\n",
    "```python\n",
    "for event in graph.stream({'messages': ('user', user_input)}):\n",
    "    for value in event.values():\n",
    "        print(value[\"messages\"][-1].content)\n",
    "```\n",
    "\n",
    "- **Outer loop** - Iterates through graph execution steps\n",
    "- **Inner loop** - Extracts values from each event\n",
    "- **`messages[-1]`** - Gets the most recent message (assistant's response)\n",
    "\n",
    "**Exit Conditions:**\n",
    "- User types: `quit`, `exit`, `bye`, or `q`\n",
    "- Breaks the loop and ends the session\n",
    "\n",
    "This creates a continuous conversation where each message builds on the previous context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20697292-5540-40d6-a787-37721497da7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The novel \"Crime and Punishment\" by Fyodor Dostoevsky is a complex and layered work that portrays several themes and ideas. Here are some of the most significant ones:\n",
      "\n",
      "1. **The Nature of Morality**: The novel explores the question of morality and whether it can be justified through rational thought or if it's based on emotions, intuition, and personal values. The protagonist, Raskolnikov, grapples with this question as he weighs his own moral code against the consequences of his actions.\n",
      "2. **Guilt and Redemption**: Through Raskolnikov's character, Dostoevsky portrays the psychological effects of guilt on an individual. As Raskolnikov struggles to come to terms with his crime, he undergoes a transformation from self-righteousness to self-awareness and ultimately seeks redemption.\n",
      "3. **The Psychological Effects of Crime**: The novel highlights the devastating consequences of committing a serious crime, both for the perpetrator and the victim's family. It shows how crime can lead to mental instability, paranoia, and despair.\n",
      "4. **Existentialism and Free Will**: \"Crime and Punishment\" explores the idea that human beings have free will and are responsible for their actions. The novel suggests that individuals must take responsibility for their choices and face the consequences of those choices.\n",
      "5. **The Role of Emotions in Decision-Making**: Dostoevsky portrays the importance of emotions, particularly empathy and compassion, in making moral decisions. Raskolnikov's inability to connect with his neighbor, Sonya, highlights the dangers of prioritizing reason over emotion.\n",
      "6. **Social Class and Economic Struggle**: The novel critiques the social class system of 19th-century Russia, highlighting the poverty, inequality, and desperation that can lead individuals to commit crimes out of necessity or desperation.\n",
      "7. **The Power of Faith and Spirituality**: Through Sonya's character, Dostoevsky portrays the redemptive power of faith and spirituality in overcoming personal struggles and finding forgiveness.\n",
      "8. **The Dangers of Intellectualism**: The novel warns against the dangers of intellectual arrogance and the tendency to rationalize or justify immoral behavior through philosophical reasoning.\n",
      "9. **The Complexity of Human Nature**: \"Crime and Punishment\" presents a nuanced portrayal of human nature, revealing that individuals are multifaceted and capable of both good and evil.\n",
      "10. **The Search for Meaning and Purpose**: Ultimately, the novel suggests that finding meaning and purpose in life is crucial for personal growth and redemption.\n",
      "\n",
      "Overall, \"Crime and Punishment\" is a thought-provoking exploration of the human condition, morality, guilt, and redemption, offering insights into the complexities of the human experience.\n",
      "--------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input('User: ')\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye',  'q']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "\n",
    "    for event in graph.stream({'messages': ('user', user_input)}):\n",
    "        for value in event.values():\n",
    "            print(f'Assistant: {value[\"messages\"][-1].content}')\n",
    "            print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8e583-81c6-4b09-84f6-66d4480af33c",
   "metadata": {},
   "source": [
    "## Tavily AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad0a00",
   "metadata": {},
   "source": [
    "### Tavily AI - Search API for Agents\n",
    "\n",
    "**Tavily** is a search API optimized for AI agents and LLM applications. It provides real-time web search capabilities with AI-friendly responses.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "**1. Basic Search**\n",
    "```python\n",
    "client.search(query='your query')\n",
    "```\n",
    "- Returns relevant web results\n",
    "- Includes URL, title, and content snippets\n",
    "\n",
    "**2. Advanced Search Options**\n",
    "- `search_depth='advanced'` - More thorough search\n",
    "- `max_results=N` - Control number of results\n",
    "- `include_images=True` - Include image results\n",
    "- `include_answer=True` - Get direct answer summary\n",
    "- `include_raw_content=False` - Exclude full HTML content\n",
    "\n",
    "**3. QnA Search**\n",
    "```python\n",
    "client.qna_search(query='question')\n",
    "```\n",
    "- Returns a direct answer to the question\n",
    "- Perfect for factual queries\n",
    "\n",
    "**Why Tavily for Agents?**\n",
    "- Responses are optimized for LLM consumption\n",
    "- Reduces token usage with concise results\n",
    "- Reliable and fast for real-time applications\n",
    "- Better than raw web scraping for agent workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ddc45e-0a80-4d9f-a9ee-eefd5d633729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4573fb0-6232-42af-9a3d-4ffcc0e214e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "362a7552-f2f6-4dfe-b031-63febaa6432b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'EUFA EURO 2024 FINAL',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://en.wikipedia.org/wiki/UEFA_Euro_2024_final',\n",
       "   'title': 'UEFA Euro 2024 final - Wikipedia',\n",
       "   'content': 'Spain won this time with Randal Kolo Muani opening the scoring for the French with a header in the 9th minute, but Yamal then equalised for the Spanish in the 21st minute with a shot to the left corner from outside the penalty area, Olmo then scored the winner for Spain in the 25th minute – this was originally given as a Jules Koundé own goal but after a review was given to Olmo – this sent Spain through to their first UEFA European Championship final since the UEFA Euro 2012 final against Italy which they won 4–0. England then won the game very late on when Palmer assisted Ollie Watkins to score in the 90th minute, sending them through to their first major tournament final outside of their home country, and their second consecutive European Championship final after appearing in the UEFA Euro 2020 final at Wembley Stadium which they lost to Italy.',\n",
       "   'score': 0.9014448,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.uefa.com/uefaeuro/history/seasons/2024/',\n",
       "   'title': 'Season 2024 | UEFA EURO 2024',\n",
       "   'content': 'Official in-depth guide to UEFA EURO 2024, including results, stats and video highlights ... 2024 final: Spain 2-1 England. Live 17/07/2024. 2024 final: Spain 2-1',\n",
       "   'score': 0.85157084,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.nbcnews.com/news/sports/spain-england-euro-final-recap-rcna161803',\n",
       "   'title': 'Spain defeats England 2-1 to win Euro 2024 final - NBC News',\n",
       "   'content': \"IE 11 is not supported. # Spain defeats England 2-1 to win Euro 2024 final. Aymeric Laporte of Spain celebrates with the UEFA Euro 2024 Henri Delaunay Trophy after his team's victory during the final match between Spain and England at Olympiastadion in Berlin on Sunday. * Add NBC News to Google. Spain defeated England 2-1 on Sunday in Berlin to claim the European Championship. Spain controlled most of the first half but failed to break through. “Our parents, the fans, everyone who has been supporting us every day. It was also a coming-out party for breakout star Yamal, a 17-year-old forward who became the youngest player ever to score at a Euros with his screamer against France in the semifinals. England once again fell short of winning its first European Championship and its first major trophy since it won the World Cup in 1966. Greg Rosenstein is the sports editor for NBC News Digital.\",\n",
       "   'score': 0.7795405,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.uefa.com/uefaeuro/match/2036211--spain-vs-england/',\n",
       "   'title': 'History: Spain 2-1 England | UEFA EURO 2024 Final',\n",
       "   'content': \"Consent to Cookies & Data processing. On this website we use cookies and similar functions to process end device information and personal data (e.g. such as IP-addresses or browser information). Image 5UEFA Champions LeagueImage 6UEFA Europa LeagueImage 7UEFA Super CupImage 8UEFA Conference LeagueImage 9UEFA Youth LeagueImage 10Under-20 Intercontinental Cup. Image 11European QualifiersImage 12UEFA EURO 2028Image 13UEFA Nations LeagueImage 14FinalissimaImage 15UEFA Under-21. Image 34: Highlights, report: Spain win record fourth EURO Live ### Highlights, report: Spain win record fourth EURO. Image 35: Kane leading England by example Live 14/07/2024 ### Highlights, report: Spain win record fourth EURO. Image 36: Kane leading England by example Live 14/07/2024 ### Player of the Match: Nico Williams. Image 37: Kane leading England by example Live 14/07/2024 ### Spain vs England preview. Image 38: Kane leading England by example Live 14/07/2024 ### Southgate's England ascendant. Image 39: Kane leading England by example Live 14/07/2024 ### Kane leading England by example.\",\n",
       "   'score': 0.756376,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.olympics.com/en/news/euro-2024-final-spain-beats-england-2-1-for-record-fourth-title',\n",
       "   'title': 'Euro 2024 final: Spain beat England 2-1 for record fourth continental ...',\n",
       "   'content': \"Spain won their fourth men's UEFA European Championship title by breaking English hearts with a 2-1 win over the Three Lions in the 2024\",\n",
       "   'score': 0.72254705,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.28,\n",
       " 'request_id': 'c8a3b389-f747-4e99-ab06-279525733cf6'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "\n",
    "# initializing a Tavily client\n",
    "client = TavilyClient(api_key=os.environ.get('TAVILY_API_KEY'))\n",
    "\n",
    "response = client.search(query='EUFA EURO 2024 FINAL')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "657c7f2f-a13a-4006-99e7-e042b7bf0bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UEFA Euro 2024 final - Wikipedia, URL: https://en.wikipedia.org/wiki/UEFA_Euro_2024_final\n",
      "Title: Season 2024 | UEFA EURO 2024, URL: https://www.uefa.com/uefaeuro/history/seasons/2024/\n",
      "Title: Spain defeats England 2-1 to win Euro 2024 final - NBC News, URL: https://www.nbcnews.com/news/sports/spain-england-euro-final-recap-rcna161803\n",
      "Title: History: Spain 2-1 England | UEFA EURO 2024 Final, URL: https://www.uefa.com/uefaeuro/match/2036211--spain-vs-england/\n",
      "Title: Euro 2024 final: Spain beat England 2-1 for record fourth continental ..., URL: https://www.olympics.com/en/news/euro-2024-final-spain-beats-england-2-1-for-record-fourth-title\n"
     ]
    }
   ],
   "source": [
    "for result in response['results']:\n",
    "    print(f\"Title: {result['title']}, URL: {result['url']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0a77b6a-2578-4bc8-b2f8-72058c6b8612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are LLM agents?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': 'LLM agents are AI systems that use large language models to autonomously perform tasks, plan actions, and interact with users. They can execute complex workflows and adapt based on context. They differ from chatbots by using memory and reasoning.',\n",
       " 'images': ['https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https://substack-post-media.s3.amazonaws.com/public/images/c3177e12-432e-4e41-814f-6febf7a35f68_1360x972.png',\n",
       "  'https://promptengineering.org/content/images/2023/08/Prompt-engineering---Large-Language-Model-LLM--Autonomous-Agent-Structure---PromptEngineering.org.jpg',\n",
       "  'https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/Untitled-1-01-1.webp',\n",
       "  'https://promptengineering.org/content/images/2023/07/Prompt-engineering---Large-Language-Model-LLM--Autonomous-Agent.jpg',\n",
       "  'https://cdn.prod.website-files.com/637e5037f3ef83b76dcfc8f9/679d0d704736b03122daf988_679d0d1a47e3f882ef4179f1_Botpress%20Blogs-8.webp'],\n",
       " 'results': [{'url': 'https://www.k2view.com/what-are-llm-agents/',\n",
       "   'title': 'What are LLM Agents? A Practical Guide',\n",
       "   'content': 'LLM agents are AI systems that leverage Large Language Models (LLMs) trained on enormous amounts of text data, to understand, imitate, and generate human language. The agents use LLMs to perform language-related tasks designed to improve decision-making and user/system (e.g., customer/chatbot) interactions.\\n\\nLLM agents are designed to provide accurate text responses based on sequential reasoning. Ideally, agents can remember past conversations, think ahead, and adjust their responses to the context of the query.\\n\\nTake, for example, a query by a new employee to an HR chatbot like: _How many vacation and sick days is one entitled to and what is the policy regarding equity options?_ [...] Competitive agents interact in adversarial settings, to train models to respond to real market conditions.React-agent LLM\\n\\n   Event-driven agents react to triggering events or changes in the environment, such as real-time alerts or notifications.\\n\\n   Rules-based agents are activated based on predefined rules and conditions, often used in monitoring systems.\\nProactive LLM agents\\n\\n   Predictive agents anticipate user needs or future events based on historical data and trends.\\n\\n   Preventive agents preempt potential problems by analyzing patterns and taking corrective measures.Interactive LLM agents\\n\\n   Question-answering agents respond to queries based on context, often using knowledge bases. [...] #### 3. Planning\\n\\nLLM agents can employchain-of-thought prompting to subdivide larger tasks into smaller, more manageable parts, and formulate specific plans for each subtask. As tasks evolve, agents can also reflect on particular plans to ensure relevance to real-world scenarios – which is critical to successful task completion.\\n\\nDuring the plan formulation stage, agents break down a large task into smaller sub-tasks. With chain-of-thought reasoning, agents can address sub-tasks one by one, allowing for greater flexibility.',\n",
       "   'score': 0.99996233,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://theblue.ai/blog/applications-of-llm-agents/',\n",
       "   'title': 'Applications of LLM Agents in various industries',\n",
       "   'content': 'LLM Agents, or Large Language Model Agents, are advanced AI Agents that utilize deep learning techniques to understand and generate human language. These intelligent agents are built upon large language models, such as GPT-4, which are trained on vast amounts of text data to develop a nuanced understanding of context, syntax, and semantics. By leveraging this sophisticated understanding, LLM Agents can perform a wide range of tasks, from answering questions and generating content to automating customer support and enhancing decision-making processes. The main intuition behind these agents is using a large language model as the central computational engine to reason through problems, plan solutions, and utilize a set of tools to execute those solutions. The LLM Agent represents a powerful [...] those solutions. The LLM Agent represents a powerful framework for solving complex tasks by leveraging an LLM as its core computational engine. Applications of LLM Agents span across various domains, including healthcare for patient diagnosis support, finance for risk assessment and fraud detection, education for personalized learning experiences, and more, demonstrating their versatility and impact in numerous fields. [...] ## The structure of LLM agents\\n\\nLLM Agents are made up of some primary components, each contributing to the agent’s ability to handle a wide range of tasks and interactions:\\n\\nThe Core   \\n The Core is the fundamental part of an LLM Agent, acting as the central processing unit, or the “brain”. The Core manages the overall logic and behavioral characteristics of the agent. It interprets input, applies reasoning, and determines the most appropriate course of action based on the agent’s capabilities and objectives. It is responsible for ensuring the agent behaves in a coherent and consistent manner, based on predefined guidelines or learned behavior patterns.',\n",
       "   'score': 0.9999615,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://blog.promptlayer.com/types-of-llm-agent/',\n",
       "   'title': '7 Types of LLM Agents: A Comprehensive Guide (2024)',\n",
       "   'content': \"Platform\\n -- Prompt Management\\n -- Evaluations\\n -- Observability\\n -- Dataset Management\\n -- Prompt Chaining\\n Docs\\n Blog\\n Case Studies\\n Careers\\n Log in\\n Contact Us\\n\\nContact Us   Log In\\n\\nBack \\n\\n# LLM Agents Explained: Types, Use Cases, and Future Trends\\n\\nBy Erich H.   Nov 21, 2024\\n\\ntype of LLM agent\\n\\nLarge Language Model (LLM) agents have rapidly evolved, becoming one of the hot topics in the tech industry. Initially designed for natural language processing tasks, LLMs can now serve as autonomous agents capable of complex decision-making and task execution.\\n\\nIn this guide, we’ll explore the basics of LLM Agents, their types (such as Conversational Agents, Task-Oriented Agents, Creative Agents, and more), real-world applications, and the emerging trends driving their evolution. [...] Whether you're a tech enthusiast, a professional exploring AI, or someone curious about how these systems work, this guide will provide valuable insights into the ever-expanding world of LLM Agents.\\n\\n## What are LLM Agents?\\n\\nLLM Agents are advanced AI systems that leverage large language models to autonomously perform tasks by interpreting inputs, planning actions, and executing them using integrated tools.\\n\\nUnlike traditional chatbots, which are limited to predefined responses, LLM Agents can exhibit complex reasoning, maintain memory of past interactions, and adapt their behavior based on environmental feedback. This enables them to handle intricate tasks across various domains, from automating workflows to providing personalized assistance\\n\\n## Different Types of LLM Agents [...] ## Different Types of LLM Agents\\n\\nIn 2024, Large Language Model (LLM) agents have diversified into specialized categories, each tailored to specific functionalities and applications. Here's an overview of the different types of LLM agents:\\n\\n### 1. Conversational Agents\\n\\nThese agents engage in natural dialogue with users, providing information, answering questions, and assisting with various tasks. They rely on LLMs to understand and generate human-like responses.\\n\\nExample: Customer support chatbots that handle inquiries and provide solutions.\\n\\n### 2. Task-Oriented Agents\\n\\nFocused on performing specific tasks or achieving predefined objectives, these agents interact with users to understand their needs and then execute actions to fulfill those needs.\",\n",
       "   'score': 0.9999584,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.truefoundry.com/blog/llm-agents',\n",
       "   'title': 'LLM Agents : The Complete Guide',\n",
       "   'content': '## What Are LLM Agents?\\n\\nLLM agents are intelligent systems built on top of Large Language Models, designed not just to respond to prompts—but to take action. They can plan, reason, use tools, maintain memory, and operate autonomously to complete multi-step tasks. In simple terms, they transform passive LLMs into goal-oriented AI entities.\\n\\nWhile a standard LLM like GPT-4 or Claude responds to a single prompt in isolation, an LLM agent has an objective and a looping process: it evaluates the task, decides what to do next, executes actions (like calling a tool or searching a database), observes the result, and continues until the goal is achieved.\\n\\nThis is possible because agents add multiple layers around the base language model: [...] A planner that breaks down goals into actionable steps\\n An execution layer that interacts with tools or APIs\\n A memory module that stores context over time\\n An observation loop that allows the agent to revise its approach\\n\\n## How Do LLM Agents Work?\\n\\nLLM agents operate by layering structure, memory, and decision-making capabilities on top of a foundational Large Language Model. At a high level, an LLM agent follows a sense-think-act loop—observing its environment or inputs, reasoning about the next step, and executing actions toward a defined goal. [...] ## Architecture of LLM Agent\\n\\nAn LLM agent is not a single model or script—it’s a modular system designed to think, remember, interact, and act autonomously. This architecture is typically made up of four core components: the agent core, memory module, tools, and planning module. These parts work together to transform a raw language model into a capable, goal-driven agent.\\n\\n1. Agent Core\\n\\nAt the center of the agent is the language model itself—often a foundation model like GPT-4, Claude, LLaMA 2, or Mistral. This component is responsible for understanding inputs, generating responses, and reasoning through tasks.',\n",
       "   'score': 0.99995637,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.salesforce.com/agentforce/llm-agents/',\n",
       "   'title': 'LLM Agents: A Complete Guide - Salesforce',\n",
       "   'content': \"Information retrieval LLM agents: RAG methods are used by these types of LLM agents to find and retrieve data from any system. Here, data retrieval is relatively straightforward. Agents excel in their ability to identify and capture relevant data and ignore extraneous information.\\n Collaborative LLM agents: Collaborative agents operate alongside or in tandem with other agents. These agents effectively operate in parallel, which makes it possible to reduce response times without losing accuracy.\\n Adaptive learning LLM agents: Adaptive agents use historical data to improve future performance. Agents evaluate past outputs and compare them to ideal results to develop new strategies. [...] We'll break down how different types of LLM agents work, what they can do, the components they require, challenges they bring, and how businesses are using these tools now and in the future.\\n\\nWhat we'll cover:\\n\\n What are LLM agents?\\n What can LLM agents do?\\n Types of LLM agents and what they can do\\n Components of an LLM agent\\n How businesses are using different types of LLM agents\\n Potential challenges of LLM agents\\n The future of LLM agents\\n Leading with LLMs\\n\\n## What are LLM agents?\\n\\nLLMs are artificial intelligence (AI) systems that use a combination of memory, planning, and sequential reasoning to generate in-depth responses to user questions in a way that is similar to how a human would respond. Here's an example: [...] Task-specific LLM agents: These agents are designed to execute narrowly defined operations such as checking on a customer's order status or updating their shipping information. Typically, task-specific agents pull from a smaller pool of data, such as those offered by small language models (SLMs).\\n Conversational LLM agents: Conversational AI agents can interact with end-users such as staff or customers and provide answers to common questions. The difference between these AI agents versus chatbot counterparts is that these agents learn over time, allowing them to produce more natural responses to user questions.\",\n",
       "   'score': 0.99992394,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.superannotate.com/blog/llm-agents',\n",
       "   'title': 'LLM agents: The ultimate guide 2025',\n",
       "   'content': 'Join our 60-minute workshop to supercharge your AI agents with actionable performance insights.\\n\\nRegister now\\n\\nSign InBook a Demo\\n\\nFeatured\\n\\nLLM\\n\\n# LLM agents: The ultimate guide 2025\\n\\nMarch 11, 2025\\n\\n8 min\\n\\nThank you for subscribing to our newsletter!\\n\\nOops! Something went wrong while submitting the form.\\n\\nBack to blog\\n\\n#### Contents\\n\\nTable of content Item\\n\\nWhen you face a problem with no simple answer, you often need to follow several steps, think carefully, and remember what you’ve already tried. LLM agents are designed for exactly these kinds of situations in language model applications. They combine thorough data analysis, strategic planning, data retrieval, and the ability to learn from past actions to solve complex issues. [...] ### What are LLM agents?\\n\\nLLM agents are advanced AI systems designed for creating complex text that requires sequential reasoning. They can think ahead, remember past conversations, and use different tools to adjust their responses based on the situation and style needed.\\n\\n### What are the core components of an LLM agent?\\n\\nLLM agents generally consist of four components: the agent or brain, which is the core language model processing and understanding language based on training data; planning, which enables breaking down complex tasks into manageable subtasks; memory, including short-term memory to track ongoing discussions and long-term memory to retain past information; and tool use, which is the capability to utilize external tools or databases to enhance responses. [...] In this article, we\\'ll explore what LLM agents are, their benefits, abilities, practical examples, and the challenges they face.\\n\\n## What are LLM agents?\\n\\nLLM agents are advanced AI systems designed for creating complex text that needs sequential reasoning. They can think ahead, remember past conversations, and use different tools to adjust their responses based on the situation and style needed.\\n\\nConsider a question in the legal field that sounds like this:\\n\\n> \"What are the potential legal outcomes of a specific type of contract breach in California?\"\\n\\nA basic LLM with a retrieval augmented generation (RAG) system can easily fetch the needed information from legal databases.\\n\\nNow, consider a more detailed scenario:',\n",
       "   'score': 0.9999125,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://developer.nvidia.com/blog/introduction-to-llm-agents/',\n",
       "   'title': 'Introduction to LLM Agents | NVIDIA Technical Blog',\n",
       "   'content': 'Technical Blog\\n\\nRelated Resources\\n\\nAgentic AI / Generative AI\\n\\n# Introduction to LLM Agents\\n\\nNov 30, 2023\\n\\nBy Tanay Varshney\\n\\nLike\\n\\nDiscuss (0)\\n\\n L\\n T\\n F\\n R\\n E\\n\\nAI-Generated Summary\\n\\nLike\\n\\nDislike\\n\\n LLM-powered agents are systems that use large language models to reason through problems, create plans, and execute tasks with the help of various tools.\\n These agents consist of key components, including an agent core, memory module, tools, and planning module, which work together to enable complex reasoning and task execution.\\n Examples of enterprise applications for LLM-powered agents include talk to your data agents, swarms of agents, recommendation and experience design agents, customized AI author agents, and multi-modal agents that can process various input types.',\n",
       "   'score': 0.9997868,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 2.14,\n",
       " 'request_id': '61577a4e-d603-49a6-8a3d-da14308237a6'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.search(\n",
    "    query='What are LLM agents?',\n",
    "    search_depth='advanced',\n",
    "    max_results=7,\n",
    "    include_images=True,\n",
    "    include_answer=True,\n",
    "    include_raw_content=False\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dac70237-229d-4c60-973f-aedbb0a1e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Madrid won the 2024 UEFA Champions League final. They defeated Borussia Dortmund 2-0. This was Real Madrid's record-extending 15th title.\n"
     ]
    }
   ],
   "source": [
    "answer = client.qna_search(query='Who won the UEFA Champions League in 2024?')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b60a94c-6b99-4dc4-b5d3-2399db1b1d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://medium.com/aimonks/reflection-agents-with-langgraph-agentic-llm-based-applications-87e43c27adc7',\n",
       "  'title': 'Reflection Agents With LangGraph | Agentic LLM Based Applications',\n",
       "  'content': 'The generator will do the generative part of an LLM, generating answers to user queries. Then the generated response (Initial Response) will be passed on to the reflect agent to reflect on it and give us constructive feedback. The constructive feedback will then be passed on to the generated agent to fine tune its initial response, we’ll do this in a loop for N number of times.\\n\\nSo, let’s move ahead and create these two agents and have the reflect agent critique the initial response manually, then we’ll move on to doing the same with LangGraph in a more sophisticated and automated manner. Open the `basic_02.py`file and have the following code inside of it. [...] A simple way to understand this is the “system 1” and “system 2” architecture, credits to the LangChain blog. In such an architecture, system 1 does all the reactive and instinctive thinking while on the other end, system 2 does the reflection and reflexion part (What is reflexion? Don’t worry about that just yet). LLM for the longest time have been playing the system 1 side of things. Introducing reflection in prompting, we can usher LLM applications closer to system 2 like way of behaving. [...] In this first article, we’ll go over what is reflection in LLM based applications. Types of reflection agents and their implementations. When to use reflection agents and much more.\\n\\n## What Is Reflection?\\n\\nReflection is a prompting strategy used to improve the quality and success rate of agents and similar AI systems. It involves prompting an LLM to reflect on and critique its past actions, sometimes incorporating additional external information such as tools and observations.',\n",
       "  'score': 0.99998164,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.analyticsvidhya.com/blog/2024/10/agentic-ai-reflection-pattern/',\n",
       "  'title': 'What is Agentic AI Reflection Pattern? - Analytics Vidhya',\n",
       "  'content': '## What is the Reflection Pattern?\\n\\nThe Reflection Pattern is an agentic AI design pattern applied to AI models, where the model generates an initial response to a prompt, evaluates this output for quality and correctness, and then refines the content based on its own feedback. The model essentially plays the dual roles of creator and critic. The process involves several iterations where the AI alternates between these two roles until the output meets a certain level of quality or a predefined stopping criterion. [...] What do you mean by Training LLMs from Scratch?\\n\\nIntro to the LangChain EcosystemCore Components of LangChainApplications of LCEL ChainsRAG using LangChainLangGraphLangSmith\\n\\nIntroduction to RAG systemsEvaluation of RAG systems\\n\\nGetting Started with LlamaIndexComponents of LlamaIndexAdvanced approaches for powerful RAG system\\n\\nIntroduction to Stable DiffusionGenerating image using Stable diffusionDiffusion modelsPrompt Engineering Concepts for Stable DiffusionMidJourneyUnderstanding Dalle 3\\n\\n# What is Agentic AI Reflection Pattern?\\n\\nPankaj Singh   Last Updated : 02 Jan, 2025\\n\\n   15  min read\\n\\nToday, in the second article of the series “Agentic AI design patterns,” we will discuss the first pattern: The Reflection Pattern. [...] Overview\\n What is the Reflection Pattern?\\n Why Use the Reflection Pattern?\\n Key Components of the Reflection Pattern\\n  + 1. Generation Step\\n  + 2. Reflection Step\\n  + 3. Iteration and Refinement\\n How the Reflection Pattern Works: Step-by-Step Flow?\\n  + Components\\n  + Flow Explained\\n Practical Implementation of Agentic AI Reflection Pattern\\n Reflection Step\\n Generation Step (2nd Iteration)\\n Reflection (2nd Iteration)\\n Generation Step (3rd Iteration)\\n  + Stopping Conditions\\n Real-World Applications of Agentic AI Reflection Pattern\\n  + Self-RAG: It Retrieves, Generates and Critique Through Self-Reflection\\n  + Self-RAG vs. Traditional RAG\\n How are Agentic AI and the Reflection Pattern Related?\\n Practical Applications of the Reflection Pattern\\n Conclusion\\n Frequently Asked Questions',\n",
       "  'score': 0.99981624,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://blog.bytebytego.com/p/top-ai-agentic-workflow-patterns',\n",
       "  'title': 'Top AI Agentic Workflow Patterns - ByteByteGo Newsletter',\n",
       "  'content': 'Here’s how the reflection cycle works in practice.\\n\\n The agent first generates an initial output based on the task or prompt it receives.\\n Then, instead of immediately presenting this output as final, the agent switches into critique mode. It examines what it just produced, looking for problems, inconsistencies, areas that lack clarity, or opportunities for improvement. This critique becomes the basis for revision.\\n The agent generates an improved version that addresses the issues it identified. Depending on the implementation, this cycle might repeat multiple times, with each iteration refining the output further.\\n\\nSee the diagram below:\\n\\nThe power of reflection becomes even more apparent when we specialize in the type of critique being performed. Some examples are as follows: [...] ### Reflection Pattern: The Self-Improving Agent\\n\\nAt its core, reflection is about having an agent review and critique its own work, then revise based on that critique. This simple idea improves output quality because it introduces an iterative refinement process that catches errors, identifies weaknesses, and enhances strengths.\\n\\nHere’s how the reflection cycle works in practice.',\n",
       "  'score': 0.99974483,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://blog.langchain.com/reflection-agents/',\n",
       "  'title': 'Reflection Agents - LangChain Blog',\n",
       "  'content': \"Check out the code to see how it's implemented. In our LangGraph implementation, we put generation + reflection steps in a single node each, and check the tree state on each loop to see if the task is solved. The (abbreviated) graph definition looks something like below:\\n\\nOnce you've created the basic outline, it's easy to expand to other tasks! For instance, this technique would suit code generation tasks well, where you the agent can write explicit unit tests and score trajectories based on test quality. [...] Skip to content\\n\\nSign in Subscribe\\n\\n# Reflection Agents\\n\\nReflection is a prompting strategy used to improve the quality and success rate of agents and similar AI systems. This post outlines how to build 3 reflection techniques using LangGraph, including implementations of Reflexion and Language Agent Tree Search.\\n\\nagents 6 min read\\n\\n### Key Links\\n\\n Simple Reflection: (Python)\\n Reflexion: (Python)\\n Language Agents Tree Search: (Python)\\n Youtube\\n\\nReflection is a prompting strategy used to improve the quality and success rate of agents and similar AI systems. It involves prompting an LLM to reflect on and critique its past actions, sometimes incorporating additional external information such as tool observations. [...] An overview of the agent loop is shown below:\\n\\nFor each step, the responder is tasked with generating a response, along with additional actions in the form of search queries. Then the revisor is prompted to reflect on the current state. The logic can be defined in LangGraph as follows:\",\n",
       "  'score': 0.99969935,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/',\n",
       "  'title': 'Agentic Design Patterns Part 2: Reflection - DeepLearning.AI',\n",
       "  'content': 'Last week, I described four design patterns for AI agentic workflows that I believe will drive significant progress this year: Reflection, Tool Use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. In this letter, I\\'d like to discuss Reflection. For a design pattern that’s relatively quick to implement, I\\'ve seen it lead to surprising performance gains. [...] Reflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applications’ results in a few cases. I hope you will try it in your own work. If you’re interested in learning more about reflection, I recommend these papers:\\n\\n “Self-Refine: Iterative Refinement with Self-Feedback,” Madaan et al. (2023)\\n “Reflexion: Language Agents with Verbal Reinforcement Learning,” Shinn et al. (2023)\\n “CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing,” Gou et al. (2024)\\n\\nI’ll discuss the other agentic design patterns in future letters.\\n\\nKeep learning!\\n\\nAndrew\\n\\nRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"\\n\\nRead \"Agentic Design Patterns Part 3, Tool Use\" [...] And we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.\\n\\nFurther, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two different agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.',\n",
       "  'score': 0.99959236,\n",
       "  'raw_content': None}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "query = 'What is the \"Reflection & Critique\" pattern used in agentic applications and LangGraph?'\n",
    "\n",
    "response = client.search(query, max_results=5, search_depth='advanced')['results']\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68a7d4d1-41d1-4b3f-86a9-3f9be95cadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the prompt\n",
    "prompt = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': f'''You are an AI critical thinker research assistant. \n",
    "        Your sole purpose is to write well written, objective and structured reports on given text.'''\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': f'''Information: \"\"\"{response}\"\"\"\n",
    "        Using the above information, answer the following query: \"\"\"{query}\"\"\" in a detailed report'''\n",
    "    }\n",
    "]\n",
    "\n",
    "# Ollama expects messages directly\n",
    "lc_messages = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a86bda9a-4b75-4a77-ace3-ab73a8dfbb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Detailed Report: Reflection & Critique Pattern**\n",
      "\n",
      "The \"Reflection & Critique\" pattern is a design approach used in agentic applications and LangGraph, which aims to improve the quality and success rate of agents and similar AI systems. This pattern involves prompting an LLM (Large Language Model) to reflect on its past actions and provide constructive criticism for improvement.\n",
      "\n",
      "**Key Components:**\n",
      "\n",
      "1. **Reflection**: The first step in the Reflection & Critique pattern involves prompting the LLM to review and analyze its previous outputs. This can be done using a variety of techniques, such as asking the model to evaluate its own performance or providing it with feedback from external sources.\n",
      "2. **Critique**: After reflection, the next step is to provide constructive criticism for improvement. This can be achieved by incorporating additional actions into the agent loop, such as search queries or unit tests, to help the LLM identify areas for improvement.\n",
      "3. **Iterative Refinement**: The Reflection & Critique pattern is designed to be an iterative process, where the LLM continues to reflect and critique its own outputs until it reaches a desired level of quality.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "1. **Improved Output Quality**: By incorporating reflection and critique into the agent loop, the LLM can identify areas for improvement and refine its output accordingly.\n",
      "2. **Increased Robustness**: The Reflection & Critique pattern helps to increase the robustness of the LLM by providing it with opportunities to test and validate its outputs.\n",
      "3. **Enhanced Learning**: By reflecting on its own outputs and receiving constructive criticism, the LLM can learn from its mistakes and improve its performance over time.\n",
      "\n",
      "**Implementation:**\n",
      "\n",
      "The Reflection & Critique pattern can be implemented using various techniques, including:\n",
      "\n",
      "1. **Simple Reflection**: This involves prompting the LLM to evaluate its own performance or provide feedback from external sources.\n",
      "2. **Reflexion**: This is a more advanced implementation of the Reflection pattern, which uses a multi-agent framework to facilitate discussion between two agents: one generates outputs and the other provides constructive criticism.\n",
      "3. **Language Agent Tree Search**: This involves incorporating search queries into the agent loop to help the LLM identify areas for improvement.\n",
      "\n",
      "**Code Example:**\n",
      "\n",
      "The LangGraph implementation of the Reflection & Critique pattern can be seen in the following code:\n",
      "```python\n",
      "import langgraph\n",
      "\n",
      "# Define the basic outline of the agent loop\n",
      "class AgentLoop:\n",
      "    def __init__(self, model, search_queries):\n",
      "        self.model = model\n",
      "        self.search_queries = search_queries\n",
      "\n",
      "    def run(self):\n",
      "        # Generate output\n",
      "        output = self.model.generate()\n",
      "\n",
      "        # Reflect on output\n",
      "        reflection = self.model.reflect(output)\n",
      "\n",
      "        # Provide constructive criticism\n",
      "        critique = self.model.critique(reflection)\n",
      "\n",
      "        # Iterate until desired quality is reached\n",
      "        while not self.model.quality_threshold_reached(critique):\n",
      "            # Refine output using search queries and feedback from external sources\n",
      "            refined_output = self.model.refine(output, critique)\n",
      "\n",
      "            # Reflect on refined output\n",
      "            reflection = self.model.reflect(refined_output)\n",
      "\n",
      "            # Provide constructive criticism\n",
      "            critique = self.model.critique(reflection)\n",
      "```\n",
      "In conclusion, the Reflection & Critique pattern is a powerful design approach that can be used to improve the quality and success rate of agentic applications and LangGraph. By incorporating reflection and critique into the agent loop, LLMs can identify areas for improvement and refine their outputs accordingly.\n"
     ]
    }
   ],
   "source": [
    "response = ChatOllama(model='llama3.2').invoke(lc_messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd937c0-af90-41ba-b8af-2f935219a2ea",
   "metadata": {},
   "source": [
    "## Enhancing the Chatbot with Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e9471",
   "metadata": {},
   "source": [
    "### Tool Integration with LangGraph\n",
    "\n",
    "Now we upgrade our chatbot to use **tools** (external functions/APIs). This transforms it from a simple chatbot into an **agent** that can take actions.\n",
    "\n",
    "**Key Changes:**\n",
    "\n",
    "**1. Define Tools**\n",
    "```python\n",
    "tool = TavilySearchResults(max_results=3)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "```\n",
    "- Create tool instances (Tavily search)\n",
    "- Bind tools to the LLM so it knows what's available\n",
    "\n",
    "**2. Add Tool Node**\n",
    "```python\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "```\n",
    "- ToolNode executes the tools requested by the LLM\n",
    "- Separate node for tool execution\n",
    "\n",
    "**3. Conditional Edges**\n",
    "```python\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "```\n",
    "- **`tools_condition`** - Checks if LLM requested tool calls\n",
    "- If yes → route to \"tools\" node\n",
    "- If no → finish (no more actions needed)\n",
    "\n",
    "**4. Return Loop**\n",
    "```python\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "```\n",
    "- After tools run, results go back to chatbot\n",
    "- Chatbot processes results and decides next step\n",
    "\n",
    "**New Graph Flow:**\n",
    "```\n",
    "START → chatbot → [has tool calls?]\n",
    "                     ↓ Yes        ↓ No\n",
    "                   tools        END\n",
    "                     ↓\n",
    "                  chatbot (loop continues...)\n",
    "```\n",
    "\n",
    "The agent can now search the web, process results, and provide informed answers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d44c5791-4256-4c2e-aa67-e3d514fd023f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Tavily API key from .env (still needed for Tavily search)\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac95aef7-cd9c-4dbf-aaa1-3c54af522e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lolen\\AppData\\Local\\Temp\\ipykernel_27348\\3584848301.py:4: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  tool = TavilySearchResults(max_results=3)\n"
     ]
    }
   ],
   "source": [
    "# defining the tools\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=3)\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a774c189-c49d-4e1e-a3d0-905b22c1400a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Inference Compute: GPT-o1 and AI Governance',\n",
       "  'url': 'https://blog.heim.xyz/inference-compute/',\n",
       "  'content': '### GPT-o1: Scaling Laws for Inference?\\n\\nGPT-o1 is OpenAI\\'s latest GPT model. Its key innovation is enhanced reasoning capabilities through a chain-of-thought process. This allows the model to \"think\" before answering, leading to better responses across various tasks. The model does this by generating additional tokens not visible to the user. These hidden tokens represent the model\\'s step-by-step reasoning. More thinking means more tokens, which requires more compute. This increased compute translates to better performance on benchmarks and tasks. [...] Researchers have found another way to increase AI capabilities: GPT-o1 leverages additional compute at inference time to reason and produce better answers, continuing the upward trend in AI capabilities.\\n This development is an incremental improvement, not a paradigm shift. We\\'ve seen inference compute leading to better capabilities before, with chain-of-thought reasoning being a prime example.\\n Increased inference compute is complementary to training compute, not a replacement. Larger pre-trained models still have an edge when given access to the same inference techniques, both aspects remain critical for advancing AI capabilities. [...] I\\'ve been thinking about inference compute\\'s role for a while. Let\\'s go through what GPT-o1 is, its high-level technical implications, my previous thoughts on inference compute, some governance implications, and the unresolved questions I have.\\n\\n### GPT-o1: Scaling Laws for Inference?',\n",
       "  'score': 0.99993074},\n",
       " {'title': 'o1: Smarter than we think (2024) – Dr Alan D. Thompson',\n",
       "  'url': 'https://lifearchitect.ai/o1/',\n",
       "  'content': 'C2. If GPT-4o is 200B Dense, then o1 could also be 200B Dense, but with significantly increased inference-time compute; equivalent to the performance of a 14T MoE model (equivalent to the performance of a model about 8× larger than GPT-4 Classic 1.76T).\\n\\nC2.1. In plain-ish English, o1 may be a 200B parameter model spending 4× thinking/reasoning before responding, and performing at the level of a 2.8T parameter model or 14T MoE model. [...] ## Size estimate\\n\\n> o1 is almost like a portal to GPT-7 or GPT-8. It’s a way to leverage the knowledge in the pre-trained model, which is a GPT-4 scale model, in a way that basically gives you the effective compute of what a GPT-7 or GPT-8 would otherwise use, to achieve that same level of intelligence. It’s a pure discontinuity on the scaling… (— Brad Lightcap, OpenAI, Cisco AI Summit, 23/Jan/2025) [...] Observations\\n\\nObservation 1. Like GPT-4o (omni), o1 is multimodal: ‘Multimodal capabilities are built into o1, aiming for state-of-the-art performance in tasks like MMMU’ (OpenAI dev Q&A).\\n\\nObservation 2. o1 significantly outperforms GPT-4 Classic 1.76T MoE and GPT-4o across benchmarks. See Smarts.\\n\\nObservation 3. GPT-4o and o1 share a training data cutoff date. gpt-4o (2024-05-13) = Oct/2023. o1 = Oct/2023.\\n\\nObservation 4. If o1-preview-128k is based on GPT-4o-128k, the inference-time compute cost has increased from $15 ➜ $60, a factor of 4× (official API).',\n",
       "  'score': 0.9998273},\n",
       " {'title': 'OpenAI o1 Guide: How It Works, Use Cases, API & More',\n",
       "  'url': 'https://www.datacamp.com/blog/open-ai-o1',\n",
       "  'content': 'OpenAI also introduced o1 pro mode, which is slightly more powerful and reliable than o1. While we briefly cover o1 pro mode in this article, we explore it in more detail in this separate article: What Is OpenAI’s O1 Pro Mode? Features, ChatGPT Pro & More.\\n\\nOpenAI has reset the counter back to 1 and named it OpenAI o1, emphasizing its distinct focus on reasoning compared to the traditional GPT lineage. This marks the start of a new OpenAI o-series, similar to the GPT series we all know.\\n\\nO1 models are not designed to replace GPT-4o in all cases. For applications requiring or consistently rapid response times, the GPT-4o and GPT-4o mini models remain the optimal choice.\\n\\nRead on to find out more about the new O1 models!\\n\\n## Develop AI Applications',\n",
       "  'score': 0.99828595}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = tool.invoke('What is GPT o1?')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a01d1629-a633-4c24-9233-5130751abcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# --- new import\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearchResults(max_results=3)\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatOllama(model='llama3.2', temperature=0.5)\n",
    "\n",
    "# tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# change the chatbot() node function. Use llm_with_tools instead of llm.\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# --- add this:\n",
    "# run the tools if they are called by adding the tools to a new node.\n",
    "# This node runs the tools requested in the last AIMessage.\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "# ---\n",
    "\n",
    "# --- add this\n",
    "# define the conditional_edges.\n",
    "# we'll use the prebuilt tools_condition in the conditional_edge to route to the ToolNode if the last message has tool calls,\n",
    "# otherwise, route to the end.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# ---\n",
    "\n",
    "# any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "# we don't need to explicitly set a finish_point because our graph already has a way to finish!\n",
    "# graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71c47170-d408-42ba-a590-afc0c03f306a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize the graph we've built. We'll use the same code as in the previous video.\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf3fd46a-9894-4c49-8d17-5c7323e5fc03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  \n",
      "--------------------------------------------------\n",
      "Assistant:  [{\"title\": \"Positional Encodings in Transformer Models\", \"url\": \"https://machinelearningmastery.com/positional-encodings-in-transformer-models/\", \"content\": \"## Understanding Positional Encodings\\n\\nConsider these two sentences: “The fox jumps over the dog” and “The dog jumps over the fox”. They contain the same words but in different orders. In recurrent neural networks, the model processes words sequentially, naturally capturing this difference. However, transformer models process all words in parallel, making them unable to distinguish between these sentences without additional information.\\n\\nPositional encodings solve this problem by providing information about each token’s position in the sequence. Each token is converted into a vector through the model’s embedding layer, with the vector size called the “hidden dimension”. Positional encoding adds position information by creating a vector of the same hidden dimension. [...] The positional encodings are added to the input in the attention module. During the dot-product operation, these encodings emphasize relationships between nearby tokens, helping the model understand context. This allows the model to distinguish between sentences with the same words in different orders.\\n\\nThe most common types of positional encodings are: [...] $$  \\n \\\\mathbf{\\\\hat{x}}\\\\_m = \\\\mathbf{R}\\\\_m\\\\mathbf{x}\\\\_m = \\\\begin{bmatrix}  \\n \\\\cos(m\\\\theta\\\\_i) & -\\\\sin(m\\\\theta\\\\_i) \\\\\\\\  \\n \\\\sin(m\\\\theta\\\\_i) & \\\\cos(m\\\\theta\\\\_i)  \\n \\\\end{bmatrix} \\\\mathbf{x}\\\\_m  \\n $$\\n\\nFor $\\\\mathbf{x}\\\\_m$ representing a pair $(i, d/2+i)$ of elements in the vector at position $m$.\\n\\nHere’s the PyTorch implementation:\", \"score\": 0.9998832}, {\"title\": \"What is Positional Encoding? | IBM\", \"url\": \"https://www.ibm.com/think/topics/positional-encoding\", \"content\": \"# What is positional encoding?\\n\\n## What is positional encoding?\\n\\nPositional encoding is a technique that injects information about the position of the words in a sequence to transformer architectures.\\n\\nThe order of words plays a fundamental part in understanding the semantic meaning of a sentence. For example, “Allen walks dog” and “dog walks Allen” have entirely different meanings despite having the same words, or tokens. When implementing natural language processing (NLP) applications by using deep learning and neural networks, we need to create a mechanism by which machines can retain the orders of words in a sentence to produce logical output. [...] For even positions:\\n\\nFor odd positions:\\n\\n : The position of the word in the sentence (for example, 0 for the first word, 1 for the second, and so on.)\\n\\n : The dimension index of the embedding vector. maps to column index. 2i will indicate an even position and 2i+1 will indicate an odd position\\n\\n : The predefined dimensionality of the token embeddings (for example, 512)\\n\\n : user-defined scaler value (for example, 10000)\\n\\n : position function for mapping position k in the input sequence to get the positional mapping\\n\\nUsing this formula, each word, at position k, will have an embedding value based on the position of the word. Take the example that we used, “Allen walks dog”, we can calculate the positional embedding for each word:\\n\\n-   = \\\"Allen\\\"\\n\\n-   = \\\"walks\\\"\\n\\n-   =\\\"dog\\\" [...] We achieve this objective by first processing each word as a vector that represents its meaning—for example, “dog” will be encoded in a high dimensional array that encodes its concept. In technical terms, each word or sub word is mapped to an input embedding of varying lengths. However, on its own, the meaning vector does not tell us where in the sentence dog appears. Positional encoding adds a second vector—one that encodes the position index, such as “first word”, or “second word”, and so on. The two vectors are then added to represent what the word is and where the word is. This resulting vector is often referred to as the positional encoding vector.\", \"score\": 0.9997749}, {\"title\": \"Positional Encoding in Transformer-Based Time Series Models\", \"url\": \"https://arxiv.org/html/2502.12370v1\", \"content\": \"A crucial aspect of employing Transformers in time series tasks is the positional encoding mechanism. Initially proposed by Vaswani et al. , fixed positional encodings utilize sinusoidal functions to embed positional information, ensuring the model can differentiate between distinct time steps. Subsequent advancements, such as learnable positional encodings and relative positional encodings introduced by Shaw et al. , have further enhanced the model’s ability to capture temporal relationships effectively. Recent innovations in positional encoding methods have further enriched Transformer-based approaches for time series analysis. [...] In this survey, we present a systematic analysis of positional encoding methods in transformer-based time series models, categorizing them into three main types: absolute positional encodings, relative positional encodings, and hybrid approaches that combine both techniques. Our methodology encompasses both theoretical analysis and empirical evaluation. We first examine the mathematical foundations and computational characteristics of each encoding method, including their parameter complexity, time complexity, and space requirements. We then evaluate these methods using two distinct transformer architectures: one incorporating batch normalization and another utilizing patch embedding, to assess how architectural choices influence the effectiveness of different positional encoding [...] particularly well-suited for evaluating positional encoding methods’ effectiveness in capturing both local and global temporal dependencies. This comprehensive evaluation reveals several key findings: advanced methods like Stochastic Positional Encoding (SPE) and Transformer with Untied Positional Encoding (TUPE)  consistently outperform traditional approaches, with performance advantages becoming more pronounced for longer sequences. We also find that the effectiveness of positional encoding methods varies significantly with sequence length, data dimensionality, and application domain. These insights provide valuable guidance for practitioners in selecting appropriate positional encoding methods based on their specific application requirements.\", \"score\": 0.9997131}]\n",
      "--------------------------------------------------\n",
      "Assistant:  Positional encodings are a technique used to inject information about the position of words in a sequence into transformer architectures. This is necessary because transformer models process all words in parallel, making it difficult for them to distinguish between sentences with the same words in different orders.\n",
      "\n",
      "The most common type of positional encoding uses sinusoidal functions to embed positional information. The formula for calculating positional encodings is:\n",
      "\n",
      "$$ \\mathbf{\\hat{x}}_m = \\mathbf{R}_m\\mathbf{x}_m = \\begin{bmatrix}  \\n \\cos(m\\theta_i) & -\\sin(m\\theta_i) \\\\\\\\  \\n \\sin(m\\theta_i) & \\cos(m\\theta_i)  \\n \\\\end{bmatrix}\\mathbf{x}_m $$\n",
      "\n",
      "where $m$ is the position of the word, $\\theta_i$ is a parameter that controls the frequency of the sinusoidal function, and $\\mathbf{x}_m$ is the input vector.\n",
      "\n",
      "Positional encodings are added to the input in the attention module, where they emphasize relationships between nearby tokens. This allows the model to understand context and distinguish between sentences with the same words in different orders.\n",
      "\n",
      "There are three main types of positional encoding methods: absolute positional encodings, relative positional encodings, and hybrid approaches that combine both techniques. Advanced methods like Stochastic Positional Encoding (SPE) and Transformer with Untied Positional Encoding (TUPE) consistently outperform traditional approaches, especially for longer sequences.\n",
      "--------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input('User: ')\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye',  'q']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "        \n",
    "    for event in graph.stream({'messages': ('user', user_input)}):\n",
    "        for value in event.values():\n",
    "            print('Assistant: ', value['messages'][-1].content)\n",
    "        print('-' * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed5669-630d-4dd9-8985-08c103dba86e",
   "metadata": {},
   "source": [
    "##  Adding Memory to the Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a530a7b",
   "metadata": {},
   "source": [
    "### Persistent Memory with Checkpointers\n",
    "\n",
    "**Problem:** Previous chatbots forget everything after the conversation ends.\n",
    "\n",
    "**Solution:** Add a **checkpointer** to persist conversation state.\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "**1. Checkpointer/Saver**\n",
    "```python\n",
    "memory = SqliteSaver.from_conn_string(':memory:')\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "```\n",
    "- **SqliteSaver** - Stores state in SQLite database\n",
    "- **MemorySaver** - Stores state in memory (lost on restart)\n",
    "- `:memory:` - In-memory SQLite (fast, temporary)\n",
    "- For persistence, use a file path: `'checkpoints.db'`\n",
    "\n",
    "**2. Thread IDs (Conversation Sessions)**\n",
    "```python\n",
    "config = {'configurable': {'thread_id': '1'}}\n",
    "```\n",
    "- Each conversation thread has a unique ID\n",
    "- Multiple users = multiple thread IDs\n",
    "- Same thread ID = same conversation history\n",
    "- Different thread ID = fresh conversation\n",
    "\n",
    "**3. How It Works**\n",
    "- After each turn, state is saved (checkpointed)\n",
    "- On next message, previous state is loaded\n",
    "- Agent remembers all previous messages in that thread\n",
    "- Can have multiple concurrent conversations with different thread IDs\n",
    "\n",
    "**Memory Benefits:**\n",
    "- Multi-turn conversations with context\n",
    "- Reference previous questions/answers\n",
    "- Build complex reasoning over time\n",
    "- Enable follow-up questions\n",
    "\n",
    "**Example Flow:**\n",
    "```python\n",
    "# First question\n",
    "graph.stream({'messages': [('user', 'What is LangGraph?')]}, \n",
    "             config={'configurable': {'thread_id': '1'}})\n",
    "\n",
    "# Follow-up (agent remembers first question!)\n",
    "graph.stream({'messages': [('user', 'How do I use it?')]}, \n",
    "             config={'configurable': {'thread_id': '1'}})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84ae5d62-1342-46e6-9188-99878eaabd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c9a57d3-9ae8-423e-8117-6e3af0977e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Tavily API key from .env (still needed for Tavily search)\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e071e131-c321-44c8-b1ac-8b8e546b193f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x226638f8b00>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearchResults(max_results=3)\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatOllama(model='llama3.2', temperature=0.5)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {'messages': [llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "graph_builder.add_node('chatbot', chatbot)\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    'chatbot',\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "graph_builder.set_entry_point('chatbot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b12114d-2b9c-44ec-90ef-be5a672a322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.memory import MemorySaver ### fix\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(':memory:')\n",
    "graph = graph_builder.compile(checkpointer=MemorySaver()) ### fix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0c3a43d-888c-48c9-bcd4-241de3fd6685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a412e83-0312-472a-8954-c459c15295e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable': {'thread_id': '1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1f7c680-afae-4407-9a46-8d498b07ffbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the lastest AI model developed by OpenAI?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (21890030-d6cd-4bd2-a2bb-581b840f756a)\n",
      " Call ID: 21890030-d6cd-4bd2-a2bb-581b840f756a\n",
      "  Args:\n",
      "    query: latest ai model openai\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Model Release Notes - OpenAI Help Center\", \"url\": \"https://help.openai.com/en/articles/9624314-model-release-notes\", \"content\": \"Introducing OpenAI o3-mini (January 31, 2025). We're excited to release o3-mini, our newest cost-efficient reasoning model optimized for coding, math, and\", \"score\": 0.78709817}, {\"title\": \"Models | OpenAI API\", \"url\": \"https://developers.openai.com/api/docs/models\", \"content\": \"o3\\no4-mini\\ngpt-4.1\\ngpt-4.1-mini\\ngpt-4.1-nano\\no1-pro\\ncomputer-use-preview\\ngpt-4o-mini-search-preview\\ngpt-4o-search-preview\\ngpt-4.5-preview\\no3-mini\\no1\\nomni-moderation-latest\\no1-mini\\no1-preview\\ngpt-4o\\ngpt-4o-audio-preview\\ngpt-4o-mini\\ngpt-4o-mini-audio-preview\\ngpt-4o-mini-realtime-preview\\ngpt-4o-realtime-preview\\ngpt-4-turbo\\nbabbage-002\\nchatgpt-4o-latest\\ngpt-5.1-codex-mini\\ncodex-mini-latest\\ndall-e-2\\ndall-e-3\\ndavinci-002\\ngpt-3.5-turbo\\ngpt-4\\ngpt-4-turbo-preview\\ngpt-4o-mini-transcribe\\ngpt-4o-mini-tts\\ngpt-4o-transcribe\\ngpt-4o-transcribe-diarize\\ngpt-5.2-chat-latest\\ngpt-5.1-chat-latest\\ngpt-5-chat-latest\\ngpt-oss-120b\\ngpt-oss-20b\\ntext-embedding-3-large\\ntext-embedding-3-small\\ntext-embedding-ada-002\\ntext-moderation-latest\\ntext-moderation-stable\\ntts-1\\ntts-1-hd\\nwhisper-1 [...] gpt-5.2\\ngpt-5-mini\\ngpt-5-nano\\ngpt-5.2-pro\\ngpt-5\\ngpt-4.1\\ngpt-oss-120b\\ngpt-oss-20b\\nsora-2\\nsora-2-pro\\no3-deep-research\\no4-mini-deep-research\\ngpt-image-1.5\\nchatgpt-image-latest\\ngpt-image-1\\ngpt-image-1-mini\\ngpt-4o-mini-tts\\ngpt-4o-transcribe\\ngpt-4o-mini-transcribe\\ngpt-realtime\\ngpt-realtime-1.5\\ngpt-audio\\ngpt-audio-1.5\\ngpt-realtime-mini\\ngpt-audio-mini\\ngpt-5-chat-latest\\nchatgpt-4o-latest\\ngpt-5.2\\ngpt-5.1\\ngpt-5\\ngpt-5-mini\\ngpt-5-nano\\ngpt-5.3-codex\\ngpt-5.2-codex\\ngpt-5.1-codex\\ngpt-5.1-codex-max\\ngpt-5-codex\\ngpt-5.2-pro\\ngpt-5-pro\\nsora-2\\nsora-2-pro\\ngpt-image-1.5\\nchatgpt-image-latest\\ngpt-image-1\\ngpt-image-1-mini\\no3-deep-research\\no4-mini-deep-research\\no3-pro\\ngpt-audio\\ngpt-audio-1.5\\ngpt-realtime\\ngpt-realtime-1.5\\ngpt-realtime-mini\\ngpt-audio-mini\\no3\\no4-mini\\ngpt-4.1\\ngpt-4.1-mini\\ngpt-4.1-nano\\no1-pro [...] OpenAI Developers\\n\\n## Search the API docs\\n\\n### Get started\\n\\n### Core concepts\\n\\n### Agents\\n\\n### Tools\\n\\n### Run and scale\\n\\n### Evaluation\\n\\n### Realtime API\\n\\n### Model optimization\\n\\n### Specialized models\\n\\n### Going live\\n\\n### Legacy APIs\\n\\n### Resources\\n\\n### Getting Started\\n\\n### Using Codex\\n\\n### Configuration\\n\\n### Administration\\n\\n### Automation\\n\\n### Learn\\n\\n### Community\\n\\n### Releases\\n\\n### Core Concepts\\n\\n### Plan\\n\\n### Build\\n\\n### Deploy\\n\\n### Guides\\n\\n### Resources\\n\\n### Guides\\n\\n### Commerce specs\\n\\n### Product feeds\\n\\n### Categories\\n\\n### Topics\\n\\n### Topics\\n\\n### Contribute\\n\\n### Recent\\n\\n### Topics\\n\\n### Get started\\n\\n### Core concepts\\n\\n### Agents\\n\\n### Tools\\n\\n### Run and scale\\n\\n### Evaluation\\n\\n### Realtime API\\n\\n### Model optimization\\n\\n### Specialized models\\n\\n### Going live\\n\\n### Legacy APIs\\n\\n### Resources\", \"score\": 0.75377536}, {\"title\": \"Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ...\", \"url\": \"https://openai.com/index/retiring-gpt-4o-and-older-models/\", \"content\": \"On February 13, 2026, alongside the previously announced retirement⁠ of GPT‑5 (Instant, Thinking, and Pro), we will retire GPT‑4o, GPT‑4.1,\", \"score\": 0.20249085}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The latest AI model developed by OpenAI is o3-mini, which was released on January 31, 2025. It is a cost-efficient reasoning model optimized for coding, math, and other tasks.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'What is the lastest AI model developed by OpenAI?'\n",
    "\n",
    "# streaming the events. \n",
    "events = graph.stream(\n",
    "    {'messages': [('user', prompt)]}, config, stream_mode='values'\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event['messages'][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f52f19f-e626-48da-a3a3-bd58f7113f52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What about Google?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (36076b61-85b6-4cf6-8468-3abc685892a8)\n",
      " Call ID: 36076b61-85b6-4cf6-8468-3abc685892a8\n",
      "  Args:\n",
      "    query: Google\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Google - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Google\", \"content\": \"Google LLC (/ˈɡuː.ɡəl/ ⓘ, GOO-gəl) is an American multinational technology corporation focused on information technology, online advertising, search engine technology, email, cloud computing, software, quantum computing, e-commerce, consumer electronics, and artificial intelligence (AI). It has been referred to as \\\"the most powerful company in the world\\\" by BBC, and is one of the world's most valuable brands. Google's parent company Alphabet Inc. has been described as a Big Tech company. [...] Google was founded on September 4, 1998, by American computer scientists Larry Page and Sergey Brin. Together, they own about 14% of its publicly listed shares and control 56% of its stockholder voting power through super-voting stock. The company went public via an initial public offering (IPO) in 2004. In 2015, Google was reorganized as a wholly owned subsidiary of Alphabet Inc. Google is Alphabet's largest subsidiary and is a holding company for Alphabet's internet properties and interests. Sundar Pichai was appointed CEO of Google on October 24, 2015, replacing Larry Page, who became the CEO of Alphabet. On December 3, 2019, Pichai also became the CEO of Alphabet. [...] Google Workspace (formerly G Suite until October 2020) is a monthly subscription offering for organizations and businesses to get access to a collection of Google's services, including Gmail, Google Drive and Google Docs, Google Sheets and Google Slides, with additional administrative tools, unique domain names, and 24/7 support. On September 24, 2012, Google launched Google for Entrepreneurs, a largely not-for-profit business incubator providing startups with co-working spaces known as Campuses, with assistance to startup founders that may include workshops, conferences, and mentorships. There are seven Campus locations: Berlin, London, Madrid, Seoul, São Paulo, Tel Aviv, and Warsaw. On March 15, 2016, Google announced the introduction of Google Analytics 360 Suite, \\\"a set of integrated\", \"score\": 0.9993436}, {\"title\": \"Google Search - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Google_Search\", \"content\": \"### Google Discover\\n\\nGoogle Discover, previously known as Google Feed, is a personalized stream of articles, videos, and other news-related content. The feed contains a \\\"mix of cards\\\" which show topics of interest based on users' interactions with Google, or topics they choose to follow directly. Cards include, \\\"links to news stories, YouTube videos, sports scores, recipes, and other content based on what [Google] determined you're most likely to be interested in at that particular moment.\\\" Users can also tell Google they're not interested in certain topics to avoid seeing future updates. [...] The main purpose of Google Search is to search for text in publicly accessible documents offered by web servers, as opposed to other data, such as images or data contained in databases. It was originally developed in 1996 by Larry Page, Sergey Brin, and Scott Hassan. The search engine would also be set up in the garage of Susan Wojcicki's Menlo Park home. In 2011, Google introduced \\\"Google Voice Search\\\" to search for spoken, rather than typed, words. In 2012, Google introduced a semantic search feature named Knowledge Graph \\\"Knowledge Graph (Google)\\\"). [...] ### Google Knowledge Panel\\n\\nA Google Knowledge Panel is a feature integrated into Google search engine result pages, designed to present a structured overview of entities such as individuals, organizations, locations, or objects directly within the search interface. This feature leverages data from Google's Knowledge Graph, a database that organizes and interconnects information about entities, enhancing the retrieval and presentation of relevant content to users.\", \"score\": 0.98549646}, {\"title\": \"Search for your career at Google.\", \"url\": \"https://www.google.com/about/careers/applications/\", \"content\": \"Search for your career at Google.\\n\\nCareers\\n\\nCareers\\n\\nCareers\\n\\nSkip navigation links\\n\\n_home_ _home_ Home Home_work\\\\_outline_ _work\\\\_outline_ Jobs Jobs_noogler\\\\_hat_ _noogler\\\\_hat_ Students Students_google_ _google_ How we work How we work_handyman_ _handyman_ How we hire How we hire_person\\\\_outline_ _person\\\\_outline_ Your career Your career\\n\\n_help\\\\_outline_, expecting or parents-to-be, criminal histories consistent with legal requirements, or any other basis protected by law. See also Google's EEO Policy, Know your rights: workplace discrimination is illegal, Belonging at Google, and How we hire.\\n\\nMore about us\\n\\n_expand\\\\_more_\\n\\nRelated information\\n\\n_expand\\\\_more_\\n\\nEqual opportunity\\n\\n_expand\\\\_more_\\n\\nImage 1: Google\", \"score\": 0.5621765}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here's the answer to your original question:\n",
      "\n",
      "Google is an American multinational technology corporation that focuses on information technology, online advertising, search engine technology, email, cloud computing, software, quantum computing, e-commerce, consumer electronics, and artificial intelligence (AI). It was founded in 1998 by Larry Page and Sergey Brin and has since become one of the world's most valuable brands. Google is a subsidiary of Alphabet Inc., which it became in 2015. The company offers various services, including Gmail, Google Drive, and Google Docs, as well as a platform for startups and entrepreneurs through its Google for Entrepreneurs program.\n"
     ]
    }
   ],
   "source": [
    "# It has memory!\n",
    "prompt = 'What about Google?'\n",
    "events = graph.stream(\n",
    "    {'messages': [('user', prompt)]}, config, stream_mode='values'\n",
    ")\n",
    "for event in events:\n",
    "    event['messages'][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "040ba00d-c5aa-447d-9ce2-8ece056ff1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What did I ask you so far?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (0dac9bd3-d31e-47d0-9f1f-74e4ffc4befb)\n",
      " Call ID: 0dac9bd3-d31e-47d0-9f1f-74e4ffc4befb\n",
      "  Args:\n",
      "    query: Google functions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"Google Cloud Functions Explained - Pluralsight\", \"url\": \"https://www.pluralsight.com/resources/blog/cloud/google-cloud-functions-explained\", \"content\": \"## Google Cloud Functions: An Introduction\\n\\nGoogle Cloud Functions is a serverless compute platform that allows you to run code in response to events without having to provision or manage servers. Because Cloud Function is a fully managed service, it is a great way to efficiently automate tasks, build microservices, and connect your applications to other cloud products and services, both on and off Google Cloud. I like to think of Cloud Functions as the \\\"glue\\\" between services that allow you to extend the built-in capabilities to achieve your programmatic goals. [...] Deploying a 2nd gen function, triggered by a audit log event such a Cloud SQL instance failover, is just as straight-forward:\\n\\n```\\ngcloud functions deploy FUNCTION_NAME --gen2 --event-filters=\\\"type=google.cloud.audit.log.v1.written\\\" --event-filters=\\\"serviceName= serviceName=cloudsql.googleapis.com\\\" --event-filters=\\\"methodName= cloudsql.instances.failover\\\" --service-account=PROJECT_NUMBER-compute@developer.gserviceaccount.com \\n```\\n\\n## Conclusion\\n\\nGoogle Cloud Functions are an essential element of today's microservice, cloud-based event architecture. Because they're serverless, they scale effortlessly as needed to connect almost any declared action to your desired reaction.\\n\\nWant to learn more? Check out the following resources: [...] Cloud Functions falls into the Functions as a Service (FaaS) category of computing. FaaS is all about the code–and just the code. With Google Cloud Functions, you have your choice of working with a range of runtimes: Go, Java, .NET Core, Node.js, PHP, Python or Ruby. Here's an example of a simple Cloud Function in Python:\", \"score\": 0.8415267}, {\"title\": \"Google Cloud Functions in 2025: What Teams Should Know\", \"url\": \"https://cloudchipr.com/blog/google-cloud-functions\", \"content\": \"## What is Google Cloud Functions ?\\n\\nCloud Run functions is Google’s Functions-as-a-Service (FaaS): single-purpose code that runs on demand, triggered by HTTP or events, without servers to manage. Under the hood, it deploys to Cloud Run and uses Eventarc for event delivery. You get simple function signatures and language runtimes, plus Cloud Run’s controls (concurrency, CPU/memory, networking).\\n\\nSupported runtimes include Node.js, Python, Go, Java, .NET, PHP, and Ruby, with lifecycle/support schedules clearly documented.\\n\\nIf you still have “1st gen” functions, Google keeps the docs available; but for new work, Cloud Run functions is the path forward. The official comparison page highlights the differences and migration considerations. [...] Log InStart Free TrialBook a Demo\\n\\nGoogle Cloud\\n\\nCloud Services\\n\\nPricing Breakdown\\n\\n# Google Cloud Functions in 2025: What Teams Should Know\\n\\nSeptember 11, 2025\\n\\n7\\n\\nmin read\\n\\nGoogle Cloud\\n\\nCloud Services\\n\\nPricing Breakdown\\n\\n## Introduction\\n\\nIf you’ve been searching for google cloud functions lately, you’ve probably noticed a new label across Google’s docs: Cloud Run functions. In August 2024, Google renamed Cloud Functions (2nd gen) to Cloud Run functions and folded it under the Cloud Run umbrella—same event-driven model, now with Cloud Run’s knobs for performance, scalability, and security.\\n\\nThis article provides a crisp Google Cloud Functions overview for 2025—how it works, pricing, differences from Cloud Run and AWS Lambda, security best practices, and when to choose each service. [...] ## Conclusion\\n\\nIn 2025, Google Cloud Functions lives as Cloud Run functions: the familiar, event-driven model on the Cloud Run platform. You still write small handlers and attach them to HTTP or Eventarc, while inheriting Cloud Run’s controls—longer timeouts, configurable concurrency, IAM/IAP, Secret Manager, and private networking. Pricing remains per-use with a practical free tier. The decision is straightforward: choose Cloud Run functions for function-style glue and lightweight APIs, Cloud Run services when you need full containers or background work, and AWS Lambda if your ecosystem is centered on AWS.\\n\\nShare this article:\\n\\n24/7 Cloud Optimization and Real Time Observability\\n\\nBook a Demo\\n\\nSchedule now\\n\\nThank you!\\n\\nYour submission has been received!\", \"score\": 0.81133276}, {\"title\": \"Cloud Functions for Firebase - Google\", \"url\": \"https://firebase.google.com/docs/functions\", \"content\": \"Cloud Functions for Firebase is a serverless framework that lets you automatically run backend code in response to events triggered by background events, HTTPS requests, the Admin SDK, or Cloud Scheduler jobs. Your JavaScript, TypeScript or Python code is stored on Google Cloud infrastructure and runs in a managed environment. There's no need to manage and scale your own servers.\\n\\nAlready using Cloud Run functions in Google Cloud? Learn more about how Firebase fits into the picture.\\n\\nGet started Use cases\\n\\n## Key capabilities\", \"score\": 0.7395922}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It seems like you asked me to search for information on Google Cloud Functions, but I couldn't find any specific question from you. However, I can try to help you with your original question.\n",
      "\n",
      "Could you please rephrase or ask a new question? I'll do my best to provide a helpful answer using the output of a tool call response.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'What did I ask you so far?'\n",
    "\n",
    "events = graph.stream(\n",
    "    {'messages': [('user', prompt)]}, config, stream_mode='values'\n",
    ")\n",
    "for event in events:\n",
    "    event['messages'][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b382ec29-a6da-48d4-bfad-4d2e008efb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What did I ask you so far?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (cfd6a049-63e3-4912-9534-57ed334871c3)\n",
      " Call ID: cfd6a049-63e3-4912-9534-57ed334871c3\n",
      "  Args:\n",
      "    query: your question so far\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"So far, do you have any questions? : r/EnglishLearning - Reddit\", \"url\": \"https://www.reddit.com/r/EnglishLearning/comments/76rnus/so_far_do_you_have_any_questions/\", \"content\": \"r/EnglishLearning icon\\n\\n# So far, do you have any questions?\\n\\nAnswer: below\\n\\nI'm presenting something. Intermittently I asked as this;\\n\\nSo far, do you have any questions?\\n\\nIs it okay to use \\\"so far\\\" with \\\"do you have any questions\\\"? Yes\\n\\nAfter saying it, I became unsure. But I already said it. So I was like 'what am I talking?' But as I became nervous about it, I happened to say it multiple times throughout my presentation......\\n\\nOther similar phrases\\n\\nDo you have any questions about what I've said so far?\\n\\nAre there any questions on what I've just said?\\n\\nDo you want to ask me anything at this point?\\n\\n# Related Answers Section\\n\\nCreate your account and connect with a world of communities.\\n\\nAnyone can view, post, and comment to this community\\n\\n## Top Posts\", \"score\": 0.5849357}, {\"title\": \"How to respond to a question such as, 'So how's your day ... - Quora\", \"url\": \"https://www.quora.com/How-do-you-respond-to-a-question-such-as-So-hows-your-day-been-that-includes-the-word-so\", \"content\": \"I reply, “Oh, not bad so far” or “Just horrifying!” depending on what’s been going on.\\n\\nProfile photo for Charliss Green\\n\\nCharliss Green\\n\\nFormer Decades Managing & Training in Corporate Offices \\n · \\nAuthor has 28.6K answers and 8.9M answer views\\n\\n · \\n\\n4y\\n\\nOriginally Answered: What would be the appropriate answer to the question, “What are you doing today?”\\n ·\\n\\nWhat would be the appropriate answer to the question, “What are you doing today?”\\n\\nTha appropriate answer would depend upon who is asking, and why..\\n\\n Nosey neighbors\\n Boss\\n Exhusband\\n My grown children\\n My parents\\n In-laws\\n\\nIcon for Motivation , Life Skills and Positivity\\n\\nMotivation , Life Skills and Positivity\\n\\nAnswered by\\n\\nSwati Rajput\\n\\n · \\nAuthor has 3K answers and 1.2M answer views\\n\\n · \\n\\nJul 9, 2024 [...] Micro-principles to choose wording:\\n\\n Mirror the asker’s tone: casual “so” → casual reply.\\n Match length to your willingness to engage: short = end; longer = invite deeper chat.\\n Use one specific detail if you want to keep conversation flowing.\\n Add a reciprocal question if you want reciprocity: “How about you?”\\n\\nExamples mapped to intent:\\n\\n1. End the exchange: “Not much. You?”\\n2. Keep it going: “Great—I finally finished a project. How’s your day?”\\n3. Share briefly: “Busy, but good—had a great lunch.”\\n4. Signal need for privacy: “Too much going on—can we talk later?”\\n\\nSelect the tone and level of disclosure that fits the relationship and desired outcome.\\n\\nRelated questions [...] Profile photo for Carol Walker\\n\\nCarol Walker\\n\\nIT Support / Systems Admin / Technical Writer\\n · \\nAuthor has 2.9K answers and 2.6M answer views\\n\\n · \\n\\n7y\\n\\nOriginally Answered: How do I answer if someone asks me the question, “How was your day”?\\n ·\\n\\nIf it's someone I don't know well, I usually say something like \\\"pretty good thanks, yourself?\\\"\\n\\nIf it's my SO when I get home I tell him a couple of highlights (good or bad), then ask how his day was.\\n\\nProfile photo for Elizabeth Henderson\\n\\nElizabeth Henderson\\n\\nFormer English Teacher.\\n · \\nAuthor has 52.8K answers and 62.3M answer views\\n\\n · \\n\\n11mo\\n\\nThe word “So” in this context makes no difference to the question’s meaning, or to my answer. It’s just a casual way of introducing a casual question.\", \"score\": 0.30775368}, {\"title\": \"50 Questions to Ask Someone Instead of “How Are You” - Medium\", \"url\": \"https://medium.com/the-ascent/50-questions-to-ask-someone-instead-of-how-are-you-9cddc96ccb86\", \"content\": \"1. What was your favorite moment thus far today?\\n2. What brings you in a good mood?\\n3. Describe to a 6-year old what you do in life?\\n4. What are 3 words that describe you best?\\n5. What always makes you smile?\\n6. How do you contribute to a better society?\\n7. What are the 3 most important aspects to support your lifestyle?\\n8. When you were little, what did you think you were going to be?\\n9. What is something you know you do differently than most people?\\n10. Is there something you need help with at this moment?\\n11. Is there someone I can connect you with?\\n12. What are you (un)secretly good at?\\n13. What talent do you wish you’d have?\\n14. How do you feel about taking risk?\\n15. What’s your most (un)healthy habit?\\n16. If there is anything you would do differently in your life, what would it be? [...] ### That should be a good start ain’t?\\n\\nIt’s up to you now.\\n\\nDon’t think, just ask!\\n\\n> Byebye to shallow “How are you’s”\\n\\nLove to hear your stories!\\n\\n## I’ll set the stage :-)\\n\\nWhat’s your favorite question?\\n\\nLife Lessons\\n\\nConversations\\n\\nSelf Improvement\\n\\nInspiration\\n\\nThe Ascent\\n\\n## Published in Ascent Publication\\n\\n145K followers\\n\\n·Last published Sep 1, 2021\\n\\nStrive for happier. Join a community of storytellers documenting the climb to happiness and fulfillment.\\n\\n## Written by Daphne Fecheyr\\n\\n584 followers\\n\\n·163 following\\n\\nLife learner. Consciously ignorant idealist. Sharing lessons learned about biomimicry, sustainable business, living abroad, being a generalist.\\n\\n## Responses (23)\\n\\nWrite a response\\n\\nWhat are your thoughts?\\n\\nKristin\\n\\nJul 28, 2023\\n\\n``` [...] What are your thoughts?\\n\\nKristin\\n\\nJul 28, 2023\\n\\n```\\n\\nI’m surprised you aren’t selling a deck of cards with all these questions on them, I’d love to have something like that around!!\\n\\n```\\n\\n25\\n\\nAlison Wisnom\\n\\nJun 1, 2020\\n\\n```\\n\\nWhen I moved from the D.C. area to Hawaii I had to change my question from “What do you do?” to “What do you like to do?” No one in Hawaii cares what you do for work. :-)\\n\\n```\\n\\n17\\n\\nmeena Ram\\n\\nJun 22, 2019\\n\\n```\\n\\nNice article Daphne. Deeper conversations has deeper meaning . I would like to join along with you :) to ask some questions\\n\\nWho is your inspiration/ role model ?\\n\\nName the simplest activity you do that gives you immense joy :))\\n\\n```\\n\\n15\\n\\n## More from Daphne Fecheyr and Ascent Publication\\n\\nIn\\n\\nHow Nature Says It.\\n\\nby\\n\\nDaphne Fecheyr\", \"score\": 0.17313468}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It seems like you're asking if I can format an answer to your original question based on a tool call response, but you didn't provide the actual tool call response or your original question. Please provide the necessary information, and I'll be happy to help!\n"
     ]
    }
   ],
   "source": [
    "# NEW THREAD => no memory\n",
    "config1 = {\"configurable\": {\"thread_id\": \"10\"}}\n",
    "\n",
    "prompt = 'What did I ask you so far?'\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", prompt)]}, config1, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5085fdbf-0c91-454c-82ba-a0d369c0e6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='What is the lastest AI model developed by OpenAI?', additional_kwargs={}, response_metadata={}, id='fb4ad7c6-46f9-4bbe-8c4e-45d65655a297'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2026-02-27T12:31:39.359905Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5935041400, 'load_duration': 5188234000, 'prompt_eval_count': 198, 'prompt_eval_duration': 293056100, 'eval_count': 21, 'eval_duration': 442500200, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019c9f15-362d-7922-9612-a406eefacf81-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'latest ai model openai'}, 'id': '21890030-d6cd-4bd2-a2bb-581b840f756a', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 198, 'output_tokens': 21, 'total_tokens': 219}), ToolMessage(content='[{\"title\": \"Model Release Notes - OpenAI Help Center\", \"url\": \"https://help.openai.com/en/articles/9624314-model-release-notes\", \"content\": \"Introducing OpenAI o3-mini (January 31, 2025). We\\'re excited to release o3-mini, our newest cost-efficient reasoning model optimized for coding, math, and\", \"score\": 0.78709817}, {\"title\": \"Models | OpenAI API\", \"url\": \"https://developers.openai.com/api/docs/models\", \"content\": \"o3\\\\no4-mini\\\\ngpt-4.1\\\\ngpt-4.1-mini\\\\ngpt-4.1-nano\\\\no1-pro\\\\ncomputer-use-preview\\\\ngpt-4o-mini-search-preview\\\\ngpt-4o-search-preview\\\\ngpt-4.5-preview\\\\no3-mini\\\\no1\\\\nomni-moderation-latest\\\\no1-mini\\\\no1-preview\\\\ngpt-4o\\\\ngpt-4o-audio-preview\\\\ngpt-4o-mini\\\\ngpt-4o-mini-audio-preview\\\\ngpt-4o-mini-realtime-preview\\\\ngpt-4o-realtime-preview\\\\ngpt-4-turbo\\\\nbabbage-002\\\\nchatgpt-4o-latest\\\\ngpt-5.1-codex-mini\\\\ncodex-mini-latest\\\\ndall-e-2\\\\ndall-e-3\\\\ndavinci-002\\\\ngpt-3.5-turbo\\\\ngpt-4\\\\ngpt-4-turbo-preview\\\\ngpt-4o-mini-transcribe\\\\ngpt-4o-mini-tts\\\\ngpt-4o-transcribe\\\\ngpt-4o-transcribe-diarize\\\\ngpt-5.2-chat-latest\\\\ngpt-5.1-chat-latest\\\\ngpt-5-chat-latest\\\\ngpt-oss-120b\\\\ngpt-oss-20b\\\\ntext-embedding-3-large\\\\ntext-embedding-3-small\\\\ntext-embedding-ada-002\\\\ntext-moderation-latest\\\\ntext-moderation-stable\\\\ntts-1\\\\ntts-1-hd\\\\nwhisper-1 [...] gpt-5.2\\\\ngpt-5-mini\\\\ngpt-5-nano\\\\ngpt-5.2-pro\\\\ngpt-5\\\\ngpt-4.1\\\\ngpt-oss-120b\\\\ngpt-oss-20b\\\\nsora-2\\\\nsora-2-pro\\\\no3-deep-research\\\\no4-mini-deep-research\\\\ngpt-image-1.5\\\\nchatgpt-image-latest\\\\ngpt-image-1\\\\ngpt-image-1-mini\\\\ngpt-4o-mini-tts\\\\ngpt-4o-transcribe\\\\ngpt-4o-mini-transcribe\\\\ngpt-realtime\\\\ngpt-realtime-1.5\\\\ngpt-audio\\\\ngpt-audio-1.5\\\\ngpt-realtime-mini\\\\ngpt-audio-mini\\\\ngpt-5-chat-latest\\\\nchatgpt-4o-latest\\\\ngpt-5.2\\\\ngpt-5.1\\\\ngpt-5\\\\ngpt-5-mini\\\\ngpt-5-nano\\\\ngpt-5.3-codex\\\\ngpt-5.2-codex\\\\ngpt-5.1-codex\\\\ngpt-5.1-codex-max\\\\ngpt-5-codex\\\\ngpt-5.2-pro\\\\ngpt-5-pro\\\\nsora-2\\\\nsora-2-pro\\\\ngpt-image-1.5\\\\nchatgpt-image-latest\\\\ngpt-image-1\\\\ngpt-image-1-mini\\\\no3-deep-research\\\\no4-mini-deep-research\\\\no3-pro\\\\ngpt-audio\\\\ngpt-audio-1.5\\\\ngpt-realtime\\\\ngpt-realtime-1.5\\\\ngpt-realtime-mini\\\\ngpt-audio-mini\\\\no3\\\\no4-mini\\\\ngpt-4.1\\\\ngpt-4.1-mini\\\\ngpt-4.1-nano\\\\no1-pro [...] OpenAI Developers\\\\n\\\\n## Search the API docs\\\\n\\\\n### Get started\\\\n\\\\n### Core concepts\\\\n\\\\n### Agents\\\\n\\\\n### Tools\\\\n\\\\n### Run and scale\\\\n\\\\n### Evaluation\\\\n\\\\n### Realtime API\\\\n\\\\n### Model optimization\\\\n\\\\n### Specialized models\\\\n\\\\n### Going live\\\\n\\\\n### Legacy APIs\\\\n\\\\n### Resources\\\\n\\\\n### Getting Started\\\\n\\\\n### Using Codex\\\\n\\\\n### Configuration\\\\n\\\\n### Administration\\\\n\\\\n### Automation\\\\n\\\\n### Learn\\\\n\\\\n### Community\\\\n\\\\n### Releases\\\\n\\\\n### Core Concepts\\\\n\\\\n### Plan\\\\n\\\\n### Build\\\\n\\\\n### Deploy\\\\n\\\\n### Guides\\\\n\\\\n### Resources\\\\n\\\\n### Guides\\\\n\\\\n### Commerce specs\\\\n\\\\n### Product feeds\\\\n\\\\n### Categories\\\\n\\\\n### Topics\\\\n\\\\n### Topics\\\\n\\\\n### Contribute\\\\n\\\\n### Recent\\\\n\\\\n### Topics\\\\n\\\\n### Get started\\\\n\\\\n### Core concepts\\\\n\\\\n### Agents\\\\n\\\\n### Tools\\\\n\\\\n### Run and scale\\\\n\\\\n### Evaluation\\\\n\\\\n### Realtime API\\\\n\\\\n### Model optimization\\\\n\\\\n### Specialized models\\\\n\\\\n### Going live\\\\n\\\\n### Legacy APIs\\\\n\\\\n### Resources\", \"score\": 0.75377536}, {\"title\": \"Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ...\", \"url\": \"https://openai.com/index/retiring-gpt-4o-and-older-models/\", \"content\": \"On February 13, 2026, alongside the previously announced retirement\\u2060 of GPT‑5 (Instant, Thinking, and Pro), we will retire GPT‑4o, GPT‑4.1,\", \"score\": 0.20249085}]', name='tavily_search_results_json', id='04a8057d-1889-4ef2-a1e5-9217a438b532', tool_call_id='21890030-d6cd-4bd2-a2bb-581b840f756a', artifact={'query': 'latest ai model openai', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://help.openai.com/en/articles/9624314-model-release-notes', 'title': 'Model Release Notes - OpenAI Help Center', 'content': \"Introducing OpenAI o3-mini (January 31, 2025). We're excited to release o3-mini, our newest cost-efficient reasoning model optimized for coding, math, and\", 'score': 0.78709817, 'raw_content': None}, {'url': 'https://developers.openai.com/api/docs/models', 'title': 'Models | OpenAI API', 'content': 'o3\\no4-mini\\ngpt-4.1\\ngpt-4.1-mini\\ngpt-4.1-nano\\no1-pro\\ncomputer-use-preview\\ngpt-4o-mini-search-preview\\ngpt-4o-search-preview\\ngpt-4.5-preview\\no3-mini\\no1\\nomni-moderation-latest\\no1-mini\\no1-preview\\ngpt-4o\\ngpt-4o-audio-preview\\ngpt-4o-mini\\ngpt-4o-mini-audio-preview\\ngpt-4o-mini-realtime-preview\\ngpt-4o-realtime-preview\\ngpt-4-turbo\\nbabbage-002\\nchatgpt-4o-latest\\ngpt-5.1-codex-mini\\ncodex-mini-latest\\ndall-e-2\\ndall-e-3\\ndavinci-002\\ngpt-3.5-turbo\\ngpt-4\\ngpt-4-turbo-preview\\ngpt-4o-mini-transcribe\\ngpt-4o-mini-tts\\ngpt-4o-transcribe\\ngpt-4o-transcribe-diarize\\ngpt-5.2-chat-latest\\ngpt-5.1-chat-latest\\ngpt-5-chat-latest\\ngpt-oss-120b\\ngpt-oss-20b\\ntext-embedding-3-large\\ntext-embedding-3-small\\ntext-embedding-ada-002\\ntext-moderation-latest\\ntext-moderation-stable\\ntts-1\\ntts-1-hd\\nwhisper-1 [...] gpt-5.2\\ngpt-5-mini\\ngpt-5-nano\\ngpt-5.2-pro\\ngpt-5\\ngpt-4.1\\ngpt-oss-120b\\ngpt-oss-20b\\nsora-2\\nsora-2-pro\\no3-deep-research\\no4-mini-deep-research\\ngpt-image-1.5\\nchatgpt-image-latest\\ngpt-image-1\\ngpt-image-1-mini\\ngpt-4o-mini-tts\\ngpt-4o-transcribe\\ngpt-4o-mini-transcribe\\ngpt-realtime\\ngpt-realtime-1.5\\ngpt-audio\\ngpt-audio-1.5\\ngpt-realtime-mini\\ngpt-audio-mini\\ngpt-5-chat-latest\\nchatgpt-4o-latest\\ngpt-5.2\\ngpt-5.1\\ngpt-5\\ngpt-5-mini\\ngpt-5-nano\\ngpt-5.3-codex\\ngpt-5.2-codex\\ngpt-5.1-codex\\ngpt-5.1-codex-max\\ngpt-5-codex\\ngpt-5.2-pro\\ngpt-5-pro\\nsora-2\\nsora-2-pro\\ngpt-image-1.5\\nchatgpt-image-latest\\ngpt-image-1\\ngpt-image-1-mini\\no3-deep-research\\no4-mini-deep-research\\no3-pro\\ngpt-audio\\ngpt-audio-1.5\\ngpt-realtime\\ngpt-realtime-1.5\\ngpt-realtime-mini\\ngpt-audio-mini\\no3\\no4-mini\\ngpt-4.1\\ngpt-4.1-mini\\ngpt-4.1-nano\\no1-pro [...] OpenAI Developers\\n\\n## Search the API docs\\n\\n### Get started\\n\\n### Core concepts\\n\\n### Agents\\n\\n### Tools\\n\\n### Run and scale\\n\\n### Evaluation\\n\\n### Realtime API\\n\\n### Model optimization\\n\\n### Specialized models\\n\\n### Going live\\n\\n### Legacy APIs\\n\\n### Resources\\n\\n### Getting Started\\n\\n### Using Codex\\n\\n### Configuration\\n\\n### Administration\\n\\n### Automation\\n\\n### Learn\\n\\n### Community\\n\\n### Releases\\n\\n### Core Concepts\\n\\n### Plan\\n\\n### Build\\n\\n### Deploy\\n\\n### Guides\\n\\n### Resources\\n\\n### Guides\\n\\n### Commerce specs\\n\\n### Product feeds\\n\\n### Categories\\n\\n### Topics\\n\\n### Topics\\n\\n### Contribute\\n\\n### Recent\\n\\n### Topics\\n\\n### Get started\\n\\n### Core concepts\\n\\n### Agents\\n\\n### Tools\\n\\n### Run and scale\\n\\n### Evaluation\\n\\n### Realtime API\\n\\n### Model optimization\\n\\n### Specialized models\\n\\n### Going live\\n\\n### Legacy APIs\\n\\n### Resources', 'score': 0.75377536, 'raw_content': None}, {'url': 'https://openai.com/index/retiring-gpt-4o-and-older-models/', 'title': 'Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ...', 'content': 'On February 13, 2026, alongside the previously announced retirement\\u2060 of GPT‑5 (Instant, Thinking, and Pro), we will retire GPT‑4o, GPT‑4.1,', 'score': 0.20249085, 'raw_content': None}], 'response_time': 3.96, 'request_id': '0d03b56c-2d2e-490e-9235-bd37bbbbabe2'}), AIMessage(content='The latest AI model developed by OpenAI is o3-mini, which was released on January 31, 2025. It is a cost-efficient reasoning model optimized for coding, math, and other tasks.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2026-02-27T12:31:46.0948554Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2396880300, 'load_duration': 20024000, 'prompt_eval_count': 1355, 'prompt_eval_duration': 1061914400, 'eval_count': 43, 'eval_duration': 1311783300, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019c9f15-5e50-7d13-9e6d-976f3b5c6734-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1355, 'output_tokens': 43, 'total_tokens': 1398}), HumanMessage(content='What about Google?', additional_kwargs={}, response_metadata={}, id='29e23a7b-0e95-4ddf-b9db-e61a2e3e6501'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2026-02-27T12:31:46.8042673Z', 'done': True, 'done_reason': 'stop', 'total_duration': 690580200, 'load_duration': 26637700, 'prompt_eval_count': 1540, 'prompt_eval_duration': 21114100, 'eval_count': 21, 'eval_duration': 635006700, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019c9f15-67bf-7100-b648-69952a54f73c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Google'}, 'id': '36076b61-85b6-4cf6-8468-3abc685892a8', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1540, 'output_tokens': 21, 'total_tokens': 1561}), ToolMessage(content='[{\"title\": \"Google - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Google\", \"content\": \"Google LLC (/ˈɡuː.ɡəl/ ⓘ, GOO-gəl) is an American multinational technology corporation focused on information technology, online advertising, search engine technology, email, cloud computing, software, quantum computing, e-commerce, consumer electronics, and artificial intelligence (AI). It has been referred to as \\\\\"the most powerful company in the world\\\\\" by BBC, and is one of the world\\'s most valuable brands. Google\\'s parent company Alphabet Inc. has been described as a Big Tech company. [...] Google was founded on September 4, 1998, by American computer scientists Larry Page and Sergey Brin. Together, they own about 14% of its publicly listed shares and control 56% of its stockholder voting power through super-voting stock. The company went public via an initial public offering (IPO) in 2004. In 2015, Google was reorganized as a wholly owned subsidiary of Alphabet Inc. Google is Alphabet\\'s largest subsidiary and is a holding company for Alphabet\\'s internet properties and interests. Sundar Pichai was appointed CEO of Google on October 24, 2015, replacing Larry Page, who became the CEO of Alphabet. On December 3, 2019, Pichai also became the CEO of Alphabet. [...] Google Workspace (formerly G Suite until October 2020) is a monthly subscription offering for organizations and businesses to get access to a collection of Google\\'s services, including Gmail, Google Drive and Google Docs, Google Sheets and Google Slides, with additional administrative tools, unique domain names, and 24/7 support. On September 24, 2012, Google launched Google for Entrepreneurs, a largely not-for-profit business incubator providing startups with co-working spaces known as Campuses, with assistance to startup founders that may include workshops, conferences, and mentorships. There are seven Campus locations: Berlin, London, Madrid, Seoul, São Paulo, Tel Aviv, and Warsaw. On March 15, 2016, Google announced the introduction of Google Analytics 360 Suite, \\\\\"a set of integrated\", \"score\": 0.9993436}, {\"title\": \"Google Search - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Google_Search\", \"content\": \"### Google Discover\\\\n\\\\nGoogle Discover, previously known as Google Feed, is a personalized stream of articles, videos, and other news-related content. The feed contains a \\\\\"mix of cards\\\\\" which show topics of interest based on users\\' interactions with Google, or topics they choose to follow directly. Cards include, \\\\\"links to news stories, YouTube videos, sports scores, recipes, and other content based on what [Google] determined you\\'re most likely to be interested in at that particular moment.\\\\\" Users can also tell Google they\\'re not interested in certain topics to avoid seeing future updates. [...] The main purpose of Google Search is to search for text in publicly accessible documents offered by web servers, as opposed to other data, such as images or data contained in databases. It was originally developed in 1996 by Larry Page, Sergey Brin, and Scott Hassan. The search engine would also be set up in the garage of Susan Wojcicki\\'s Menlo Park home. In 2011, Google introduced \\\\\"Google Voice Search\\\\\" to search for spoken, rather than typed, words. In 2012, Google introduced a semantic search feature named Knowledge Graph \\\\\"Knowledge Graph (Google)\\\\\"). [...] ### Google Knowledge Panel\\\\n\\\\nA Google Knowledge Panel is a feature integrated into Google search engine result pages, designed to present a structured overview of entities such as individuals, organizations, locations, or objects directly within the search interface. This feature leverages data from Google\\'s Knowledge Graph, a database that organizes and interconnects information about entities, enhancing the retrieval and presentation of relevant content to users.\", \"score\": 0.98549646}, {\"title\": \"Search for your career at Google.\", \"url\": \"https://www.google.com/about/careers/applications/\", \"content\": \"Search for your career at Google.\\\\n\\\\nCareers\\\\n\\\\nCareers\\\\n\\\\nCareers\\\\n\\\\nSkip navigation links\\\\n\\\\n_home_ _home_ Home Home_work\\\\\\\\_outline_ _work\\\\\\\\_outline_ Jobs Jobs_noogler\\\\\\\\_hat_ _noogler\\\\\\\\_hat_ Students Students_google_ _google_ How we work How we work_handyman_ _handyman_ How we hire How we hire_person\\\\\\\\_outline_ _person\\\\\\\\_outline_ Your career Your career\\\\n\\\\n_help\\\\\\\\_outline_, expecting or parents-to-be, criminal histories consistent with legal requirements, or any other basis protected by law. See also Google\\'s EEO Policy, Know your rights: workplace discrimination is illegal, Belonging at Google, and How we hire.\\\\n\\\\nMore about us\\\\n\\\\n_expand\\\\\\\\_more_\\\\n\\\\nRelated information\\\\n\\\\n_expand\\\\\\\\_more_\\\\n\\\\nEqual opportunity\\\\n\\\\n_expand\\\\\\\\_more_\\\\n\\\\nImage 1: Google\", \"score\": 0.5621765}]', name='tavily_search_results_json', id='7283d65b-f015-44ad-bf23-7f7ce94033b5', tool_call_id='36076b61-85b6-4cf6-8468-3abc685892a8', artifact={'query': 'Google', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://en.wikipedia.org/wiki/Google', 'title': 'Google - Wikipedia', 'content': 'Google LLC (/ˈɡuː.ɡəl/ ⓘ, GOO-gəl) is an American multinational technology corporation focused on information technology, online advertising, search engine technology, email, cloud computing, software, quantum computing, e-commerce, consumer electronics, and artificial intelligence (AI). It has been referred to as \"the most powerful company in the world\" by BBC, and is one of the world\\'s most valuable brands. Google\\'s parent company Alphabet Inc. has been described as a Big Tech company. [...] Google was founded on September 4, 1998, by American computer scientists Larry Page and Sergey Brin. Together, they own about 14% of its publicly listed shares and control 56% of its stockholder voting power through super-voting stock. The company went public via an initial public offering (IPO) in 2004. In 2015, Google was reorganized as a wholly owned subsidiary of Alphabet Inc. Google is Alphabet\\'s largest subsidiary and is a holding company for Alphabet\\'s internet properties and interests. Sundar Pichai was appointed CEO of Google on October 24, 2015, replacing Larry Page, who became the CEO of Alphabet. On December 3, 2019, Pichai also became the CEO of Alphabet. [...] Google Workspace (formerly G Suite until October 2020) is a monthly subscription offering for organizations and businesses to get access to a collection of Google\\'s services, including Gmail, Google Drive and Google Docs, Google Sheets and Google Slides, with additional administrative tools, unique domain names, and 24/7 support. On September 24, 2012, Google launched Google for Entrepreneurs, a largely not-for-profit business incubator providing startups with co-working spaces known as Campuses, with assistance to startup founders that may include workshops, conferences, and mentorships. There are seven Campus locations: Berlin, London, Madrid, Seoul, São Paulo, Tel Aviv, and Warsaw. On March 15, 2016, Google announced the introduction of Google Analytics 360 Suite, \"a set of integrated', 'score': 0.9993436, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/Google_Search', 'title': 'Google Search - Wikipedia', 'content': '### Google Discover\\n\\nGoogle Discover, previously known as Google Feed, is a personalized stream of articles, videos, and other news-related content. The feed contains a \"mix of cards\" which show topics of interest based on users\\' interactions with Google, or topics they choose to follow directly. Cards include, \"links to news stories, YouTube videos, sports scores, recipes, and other content based on what [Google] determined you\\'re most likely to be interested in at that particular moment.\" Users can also tell Google they\\'re not interested in certain topics to avoid seeing future updates. [...] The main purpose of Google Search is to search for text in publicly accessible documents offered by web servers, as opposed to other data, such as images or data contained in databases. It was originally developed in 1996 by Larry Page, Sergey Brin, and Scott Hassan. The search engine would also be set up in the garage of Susan Wojcicki\\'s Menlo Park home. In 2011, Google introduced \"Google Voice Search\" to search for spoken, rather than typed, words. In 2012, Google introduced a semantic search feature named Knowledge Graph \"Knowledge Graph (Google)\"). [...] ### Google Knowledge Panel\\n\\nA Google Knowledge Panel is a feature integrated into Google search engine result pages, designed to present a structured overview of entities such as individuals, organizations, locations, or objects directly within the search interface. This feature leverages data from Google\\'s Knowledge Graph, a database that organizes and interconnects information about entities, enhancing the retrieval and presentation of relevant content to users.', 'score': 0.98549646, 'raw_content': None}, {'url': 'https://www.google.com/about/careers/applications/', 'title': 'Search for your career at Google.', 'content': \"Search for your career at Google.\\n\\nCareers\\n\\nCareers\\n\\nCareers\\n\\nSkip navigation links\\n\\n_home_ _home_ Home Home_work\\\\_outline_ _work\\\\_outline_ Jobs Jobs_noogler\\\\_hat_ _noogler\\\\_hat_ Students Students_google_ _google_ How we work How we work_handyman_ _handyman_ How we hire How we hire_person\\\\_outline_ _person\\\\_outline_ Your career Your career\\n\\n_help\\\\_outline_, expecting or parents-to-be, criminal histories consistent with legal requirements, or any other basis protected by law. See also Google's EEO Policy, Know your rights: workplace discrimination is illegal, Belonging at Google, and How we hire.\\n\\nMore about us\\n\\n_expand\\\\_more_\\n\\nRelated information\\n\\n_expand\\\\_more_\\n\\nEqual opportunity\\n\\n_expand\\\\_more_\\n\\nImage 1: Google\", 'score': 0.5621765, 'raw_content': None}], 'response_time': 1.08, 'request_id': 'c8f404e6-979f-49cf-8f9f-b32749a2ddcc'}), AIMessage(content=\"Here's the answer to your original question:\\n\\nGoogle is an American multinational technology corporation that focuses on information technology, online advertising, search engine technology, email, cloud computing, software, quantum computing, e-commerce, consumer electronics, and artificial intelligence (AI). It was founded in 1998 by Larry Page and Sergey Brin and has since become one of the world's most valuable brands. Google is a subsidiary of Alphabet Inc., which it became in 2015. The company offers various services, including Gmail, Google Drive, and Google Docs, as well as a platform for startups and entrepreneurs through its Google for Entrepreneurs program.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2026-02-27T12:31:52.4966607Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4266770100, 'load_duration': 24670400, 'prompt_eval_count': 1208, 'prompt_eval_duration': 778045100, 'eval_count': 129, 'eval_duration': 3458329600, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019c9f15-7003-7701-8cfb-24e99afa05b6-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1208, 'output_tokens': 129, 'total_tokens': 1337}), HumanMessage(content='What did I ask you so far?', additional_kwargs={}, response_metadata={}, id='4e1f21d0-e280-49ba-813d-1e68563953d1'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2026-02-27T12:31:53.3386657Z', 'done': True, 'done_reason': 'stop', 'total_duration': 783625400, 'load_duration': 77313300, 'prompt_eval_count': 1483, 'prompt_eval_duration': 27363000, 'eval_count': 22, 'eval_duration': 652026800, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019c9f15-80e6-7ed0-b3ee-35dd926d3a74-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Google functions'}, 'id': '0dac9bd3-d31e-47d0-9f1f-74e4ffc4befb', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1483, 'output_tokens': 22, 'total_tokens': 1505}), ToolMessage(content='[{\"title\": \"Google Cloud Functions Explained - Pluralsight\", \"url\": \"https://www.pluralsight.com/resources/blog/cloud/google-cloud-functions-explained\", \"content\": \"## Google Cloud Functions: An Introduction\\\\n\\\\nGoogle Cloud Functions is a serverless compute platform that allows you to run code in response to events without having to provision or manage servers. Because Cloud Function is a fully managed service, it is a great way to efficiently automate tasks, build microservices, and connect your applications to other cloud products and services, both on and off Google Cloud. I like to think of Cloud Functions as the \\\\\"glue\\\\\" between services that allow you to extend the built-in capabilities to achieve your programmatic goals. [...] Deploying a 2nd gen function, triggered by a audit log event such a Cloud SQL instance failover, is just as straight-forward:\\\\n\\\\n```\\\\ngcloud functions deploy FUNCTION_NAME --gen2 --event-filters=\\\\\"type=google.cloud.audit.log.v1.written\\\\\" --event-filters=\\\\\"serviceName= serviceName=cloudsql.googleapis.com\\\\\" --event-filters=\\\\\"methodName= cloudsql.instances.failover\\\\\" --service-account=PROJECT_NUMBER-compute@developer.gserviceaccount.com \\\\n```\\\\n\\\\n## Conclusion\\\\n\\\\nGoogle Cloud Functions are an essential element of today\\'s microservice, cloud-based event architecture. Because they\\'re serverless, they scale effortlessly as needed to connect almost any declared action to your desired reaction.\\\\n\\\\nWant to learn more? Check out the following resources: [...] Cloud Functions falls into the Functions as a Service (FaaS) category of computing. FaaS is all about the code–and just the code. With Google Cloud Functions, you have your choice of working with a range of runtimes: Go, Java, .NET Core, Node.js, PHP, Python or Ruby. Here\\'s an example of a simple Cloud Function in Python:\", \"score\": 0.8415267}, {\"title\": \"Google Cloud Functions in 2025: What Teams Should Know\", \"url\": \"https://cloudchipr.com/blog/google-cloud-functions\", \"content\": \"## What is Google Cloud Functions ?\\\\n\\\\nCloud Run functions is Google’s Functions-as-a-Service (FaaS): single-purpose code that runs on demand, triggered by HTTP or events, without servers to manage. Under the hood, it deploys to Cloud Run and uses Eventarc for event delivery. You get simple function signatures and language runtimes, plus Cloud Run’s controls (concurrency, CPU/memory, networking).\\\\n\\\\nSupported runtimes include Node.js, Python, Go, Java, .NET, PHP, and Ruby, with lifecycle/support schedules clearly documented.\\\\n\\\\nIf you still have “1st gen” functions, Google keeps the docs available; but for new work, Cloud Run functions is the path forward. The official comparison page highlights the differences and migration considerations. [...] Log InStart Free TrialBook a Demo\\\\n\\\\nGoogle Cloud\\\\n\\\\nCloud Services\\\\n\\\\nPricing Breakdown\\\\n\\\\n# Google Cloud Functions in 2025: What Teams Should Know\\\\n\\\\nSeptember 11, 2025\\\\n\\\\n7\\\\n\\\\nmin read\\\\n\\\\nGoogle Cloud\\\\n\\\\nCloud Services\\\\n\\\\nPricing Breakdown\\\\n\\\\n## Introduction\\\\n\\\\nIf you’ve been searching for google cloud functions lately, you’ve probably noticed a new label across Google’s docs: Cloud Run functions. In August 2024, Google renamed Cloud Functions (2nd gen) to Cloud Run functions and folded it under the Cloud Run umbrella—same event-driven model, now with Cloud Run’s knobs for performance, scalability, and security.\\\\n\\\\nThis article provides a crisp Google Cloud Functions overview for 2025—how it works, pricing, differences from Cloud Run and AWS Lambda, security best practices, and when to choose each service. [...] ## Conclusion\\\\n\\\\nIn 2025, Google Cloud Functions lives as Cloud Run functions: the familiar, event-driven model on the Cloud Run platform. You still write small handlers and attach them to HTTP or Eventarc, while inheriting Cloud Run’s controls—longer timeouts, configurable concurrency, IAM/IAP, Secret Manager, and private networking. Pricing remains per-use with a practical free tier. The decision is straightforward: choose Cloud Run functions for function-style glue and lightweight APIs, Cloud Run services when you need full containers or background work, and AWS Lambda if your ecosystem is centered on AWS.\\\\n\\\\nShare this article:\\\\n\\\\n24/7 Cloud Optimization and Real Time Observability\\\\n\\\\nBook a Demo\\\\n\\\\nSchedule now\\\\n\\\\nThank you!\\\\n\\\\nYour submission has been received!\", \"score\": 0.81133276}, {\"title\": \"Cloud Functions for Firebase - Google\", \"url\": \"https://firebase.google.com/docs/functions\", \"content\": \"Cloud Functions for Firebase is a serverless framework that lets you automatically run backend code in response to events triggered by background events, HTTPS requests, the Admin SDK, or Cloud Scheduler jobs. Your JavaScript, TypeScript or Python code is stored on Google Cloud infrastructure and runs in a managed environment. There\\'s no need to manage and scale your own servers.\\\\n\\\\nAlready using Cloud Run functions in Google Cloud? Learn more about how Firebase fits into the picture.\\\\n\\\\nGet started Use cases\\\\n\\\\n## Key capabilities\", \"score\": 0.7395922}]', name='tavily_search_results_json', id='b52800aa-10d7-4b71-8792-de22fa7e4732', tool_call_id='0dac9bd3-d31e-47d0-9f1f-74e4ffc4befb', artifact={'query': 'Google functions', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.pluralsight.com/resources/blog/cloud/google-cloud-functions-explained', 'title': 'Google Cloud Functions Explained - Pluralsight', 'content': '## Google Cloud Functions: An Introduction\\n\\nGoogle Cloud Functions is a serverless compute platform that allows you to run code in response to events without having to provision or manage servers. Because Cloud Function is a fully managed service, it is a great way to efficiently automate tasks, build microservices, and connect your applications to other cloud products and services, both on and off Google Cloud. I like to think of Cloud Functions as the \"glue\" between services that allow you to extend the built-in capabilities to achieve your programmatic goals. [...] Deploying a 2nd gen function, triggered by a audit log event such a Cloud SQL instance failover, is just as straight-forward:\\n\\n```\\ngcloud functions deploy FUNCTION_NAME --gen2 --event-filters=\"type=google.cloud.audit.log.v1.written\" --event-filters=\"serviceName= serviceName=cloudsql.googleapis.com\" --event-filters=\"methodName= cloudsql.instances.failover\" --service-account=PROJECT_NUMBER-compute@developer.gserviceaccount.com \\n```\\n\\n## Conclusion\\n\\nGoogle Cloud Functions are an essential element of today\\'s microservice, cloud-based event architecture. Because they\\'re serverless, they scale effortlessly as needed to connect almost any declared action to your desired reaction.\\n\\nWant to learn more? Check out the following resources: [...] Cloud Functions falls into the Functions as a Service (FaaS) category of computing. FaaS is all about the code–and just the code. With Google Cloud Functions, you have your choice of working with a range of runtimes: Go, Java, .NET Core, Node.js, PHP, Python or Ruby. Here\\'s an example of a simple Cloud Function in Python:', 'score': 0.8415267, 'raw_content': None}, {'url': 'https://cloudchipr.com/blog/google-cloud-functions', 'title': 'Google Cloud Functions in 2025: What Teams Should Know', 'content': '## What is Google Cloud Functions ?\\n\\nCloud Run functions is Google’s Functions-as-a-Service (FaaS): single-purpose code that runs on demand, triggered by HTTP or events, without servers to manage. Under the hood, it deploys to Cloud Run and uses Eventarc for event delivery. You get simple function signatures and language runtimes, plus Cloud Run’s controls (concurrency, CPU/memory, networking).\\n\\nSupported runtimes include Node.js, Python, Go, Java, .NET, PHP, and Ruby, with lifecycle/support schedules clearly documented.\\n\\nIf you still have “1st gen” functions, Google keeps the docs available; but for new work, Cloud Run functions is the path forward. The official comparison page highlights the differences and migration considerations. [...] Log InStart Free TrialBook a Demo\\n\\nGoogle Cloud\\n\\nCloud Services\\n\\nPricing Breakdown\\n\\n# Google Cloud Functions in 2025: What Teams Should Know\\n\\nSeptember 11, 2025\\n\\n7\\n\\nmin read\\n\\nGoogle Cloud\\n\\nCloud Services\\n\\nPricing Breakdown\\n\\n## Introduction\\n\\nIf you’ve been searching for google cloud functions lately, you’ve probably noticed a new label across Google’s docs: Cloud Run functions. In August 2024, Google renamed Cloud Functions (2nd gen) to Cloud Run functions and folded it under the Cloud Run umbrella—same event-driven model, now with Cloud Run’s knobs for performance, scalability, and security.\\n\\nThis article provides a crisp Google Cloud Functions overview for 2025—how it works, pricing, differences from Cloud Run and AWS Lambda, security best practices, and when to choose each service. [...] ## Conclusion\\n\\nIn 2025, Google Cloud Functions lives as Cloud Run functions: the familiar, event-driven model on the Cloud Run platform. You still write small handlers and attach them to HTTP or Eventarc, while inheriting Cloud Run’s controls—longer timeouts, configurable concurrency, IAM/IAP, Secret Manager, and private networking. Pricing remains per-use with a practical free tier. The decision is straightforward: choose Cloud Run functions for function-style glue and lightweight APIs, Cloud Run services when you need full containers or background work, and AWS Lambda if your ecosystem is centered on AWS.\\n\\nShare this article:\\n\\n24/7 Cloud Optimization and Real Time Observability\\n\\nBook a Demo\\n\\nSchedule now\\n\\nThank you!\\n\\nYour submission has been received!', 'score': 0.81133276, 'raw_content': None}, {'url': 'https://firebase.google.com/docs/functions', 'title': 'Cloud Functions for Firebase - Google', 'content': \"Cloud Functions for Firebase is a serverless framework that lets you automatically run backend code in response to events triggered by background events, HTTPS requests, the Admin SDK, or Cloud Scheduler jobs. Your JavaScript, TypeScript or Python code is stored on Google Cloud infrastructure and runs in a managed environment. There's no need to manage and scale your own servers.\\n\\nAlready using Cloud Run functions in Google Cloud? Learn more about how Firebase fits into the picture.\\n\\nGet started Use cases\\n\\n## Key capabilities\", 'score': 0.7395922, 'raw_content': None}], 'response_time': 2.21, 'request_id': '0480e841-1e08-4259-b5fb-0aff6f8f1319'}), AIMessage(content=\"It seems like you asked me to search for information on Google Cloud Functions, but I couldn't find any specific question from you. However, I can try to help you with your original question.\\n\\nCould you please rephrase or ask a new question? I'll do my best to provide a helpful answer using the output of a tool call response.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2026-02-27T12:31:59.0248776Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3078192400, 'load_duration': 63146100, 'prompt_eval_count': 1324, 'prompt_eval_duration': 975047800, 'eval_count': 70, 'eval_duration': 2022616000, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019c9f15-8e27-76e3-868b-5227353edc86-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1324, 'output_tokens': 70, 'total_tokens': 1394})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113d84-f58c-65f9-800d-9d62f8ba3b6f'}}, metadata={'source': 'loop', 'step': 13, 'parents': {}}, created_at='2026-02-27T12:31:59.027762+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f113d84-d81a-650a-800c-d53d8ec5d739'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "959688de-a791-41fb-bb10-fea8309d5bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
